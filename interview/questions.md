# 问题集锦

因为每次面试都要刷一遍面试题，对于一些平时少用的点也比较容易忘记，过后再复习一遍，比较浪费时间。所以这里总结一下，方便以后查看。

当前版本：`C++`

更新时间：`2020-03-10`

## 第一部分

暂缺，目前一般都是在线笔试，参考`编程部分`

## 第二部分

**Tips：问答部分多准备一些实现原理性的东西**

### C++虚函数实现原理

C++中的虚函数（Virtual Function）是用来实现`动态多态性(多态)`的，指的是当基类指针调用派生类中的成员函数。如果基类指针指向不同的派生类，则它调用的同一个函数就可以实现不同的逻辑，这种机制可以让基类指针有“多种形态”，它的实现依赖于`虚函数表（Virtual Table）`。`虚函数表`是指在每个包含虚函数的类中都存在一个函数地址的数组。

虚函数形式：`使用virtual关键字修饰的成员函数`

虚函数表的地址总是在对象实例的最前面的位置，其后依次是对象实例的成员。所以我们可以通过对象实例的地址（首地址）得到虚函数表的地址。并进行调用。

假如有如下定义：`Base b;`则在32bit内存寻址的操作系统下（int==32bit）：

虚函数表地址`vtptr`的值就是：`(int*)*(int*)&b`

第一个虚函数`vfunc1`的地址就是：`*(int*)*(int*)&b`

第二个虚函数`vfunc2`的地址就是：`*( (int*)*(int*)&b + 1 )`

虚函数在多态上发挥的威力要借助继承才能实现，继承分为：单继承、多继承。

#### 单继承

- 子类`未覆盖`父类虚函数表

1. 虚函数按照其声明顺序放在表中
2. 父类的虚函数在子类的虚函数之前

- 子类`覆盖`父类虚函数表

1. 覆盖的`f()`函数被放在了虚表中原来父类虚函数的位置
2. 没有被覆盖的函数依旧

#### 多继承

- 子类`未覆盖`父类虚函数表

1. 每个父类都有自己的虚表
2. 子类的成员函数被放在了第一个父类的表中。（所谓的第一个父类是按照声明的顺序来判断的）

这样做就是为了解决不同的父类类型的指针指向同一个子类实例，而能够调用到实际的函数。

- 子类`覆盖`父类虚函数表

1. 所有父类虚表中`f()`均被替换成子类的函数指针
2. 其他同`未覆盖`

这样，就可以使用任意静态类型的父类来指向子类，并调用父类的`f()`。



### C++编码，运算符重载

为什么上一章节多态里面为什么C++没有设置`返回值重载`呢？

因为，C++调用一个函数是可以忽略其返回值的，在这种情况下编译器就无法根据返回值来确定调用哪一个函数。所以，重载不能用返回值类型来区别。

运算符重载，其实就是将运算符看做特殊名称的函数。例如：

```c++
Box operator+(const Box&);
```

有一个不可重载的运算符列表：

- `.`：成员访问运算符
- `.*`,`->*`：成员指针访问运算符
- `::`：域运算符
- `sizeof`：长度运算符
- `?:`：条件运算符
- `#`：预处理运算符

### 分布式系统雪崩

- 定义

简单来说，由于服务提供者A不可用，到时服务调用者B对A的请求阻塞，没有相关的机制通知或解决请求阻塞，导致在服务调用者B对A请求的阻塞越来越多，阻塞请求变多并且不断对A进行请求重试导致服务调用者B所在的系统的资源会被耗尽，而服务调用者B所在的系统可能并不会只对A的调用，还有存在对其他服务提供者的调用，因为调用A把系统资源已经耗尽了，导致也无法处理对非A请求，而且这种不可用可能沿请求调用链向上传递，比如说服务调用者C会调用B的服务，因为B所在的系统不可用，导致C也不可用，这样级联导致阻塞请求越来越多，表现为多个系统都不可用了，这种现象被**“雪崩效应”**。

- 产生原因

复杂分布式架构的应用程序有许多依赖，其中每一个在某些时候都会不可避免的发生失败。如果这个主应用没有从哪些外部失败隔离，那么就会有被拖垮的风险。

> 服务提供者不可用-->服务调用者请求重试-->服务调用者所在系统资源耗尽-->服务调用者不可用

一个数字我们应该关注一下，可能更加有助于我们理解服务器雪崩。

例如，1个应用依赖30个服务，每个服务有99.99%可用，那么预期：

>  99.99<sup>2</sup> = 99.7%的正常运行时间
>
> 10亿次请求中有0.3% = 3,000,000次失败
>
> 2小时停机时间/月，即使所有的依赖都有很好的正常运行时间

**服务提供者不可用**

1. 硬件故障，如服务器宕机，机房断电
2. 程序bug，如JVM长时间FullGC
3. 缓存击穿，一般发生在缓存应用重启，所有缓存被清空，以及短时间大量缓存失效时。大量的缓存请求不命中，使请求直击后端，总成服务提供者超负荷运行，引起服务不可用
4. 流量激增，如异常流量，失败重试加大流量等

**服务调用者重试**

1. 用户重试，不断刷新页面甚至提交表单
2. 代码逻辑重试，在代码中加入异常情况下，请求重试的功能，这在因为网络抖动导致请求超时的情况下是很有用的。但对服务提供者本身不可用情况下，会加大对服务提供者的请求流量负担。

**服务调用者不可用**

1. 同步等待造成的资源耗尽，当调用者使用同步调用时，会产生大量的等待线程占用系统资源。一旦线程资源被耗尽，服务调用者提供的服务也将处于不可用状态。

- 如何防止

应对策略从造成雪崩的原因出发，提供不同的原因下的解决方案：

1. 硬件故障：多机房容灾、异地多活等
2. 程序bug：修改程序bug、及时释放资源等
3. 缓存穿透：缓存预加载、缓存异步加载等
4. 流量激增：服务自动扩容、流量控制（限流、关闭重试）等
5. 同步等待：资源隔离、MQ解耦、不可用服务调用快速失败等。资源隔离通常指不同服务调用采用不同的线程池；不可用服务调用快速失败一般通过**`熔断和超时`**两种机制的结合。如使用Hystrix做故障隔离，熔断器机制等可以解决依赖服务不可用的问题。

通过实践发现，线程同步等待是最常见引发的雪崩效应的场景。

**超时策略**

如果是一个服务会被系统中的其他部分频繁调用，一个部分的故障可能会导致级联故障。例如，调用服务的操作可以配置为执行超市，如果服务为能在这个时间内响应，将回复一个失败消息。然而，这种策略可能会导致许多兵法请求到同一个操作被阻塞，知道超时期限届满。这些阻塞的请求可能会存储关键的系统资源，如内存、线程、数据库连接等。因此，这些资源可能会枯竭，导致需要使用相同的资源系统故障。在这种情况下，它将是优选的操作立即失败。设置较短的超时可能有助于解决这个问题，但是一个操作请求从发出到收到成功或者失败的消息需要的时间是不确定的。

**熔断策略**

熔断器的模式使用断路器来检测故障是否已得到解决，防止请求反复尝试执行一个可能会失败的操作，从而减少等待纠正故障的时间，相对与超时策略更加灵活。

举例一个熔断功能原理：

Hystrix提供的熔断器就有类似功能，当在一定时间段内服务调用方调用服务提供方的服务的次数达到设定的阈值，并且出错的次数也达到设置的出错阈值，就会进行服务降级，让服务调用方之间执行本地设置的降级策略，而不再发起远程调用（比较常见的策略就是`直通`）。但是Hystrix提供的熔断器具有自我反馈，自我恢复的功能，Hystrix会根据调用接口的情况，让熔断器在`closed`,`open`,`half-open`三种状态之间自动切换。

`open`：状态说明打开熔断，也局势服务调用方执行本地降级策略，不进行远程调用。

`closed`：状态说明关闭了熔断，这时候服务调用方直接发起远程调用。

`half-open`：状态，则是一个中间状态，当熔断器处于这种状态的时候，直接发起远程调用。

### TCP拥塞控制算法

TCP协议通过维护一个拥塞窗口来进行拥塞控制，拥塞控制的原则是：只要网络中没有出现拥塞，拥塞窗口的值就可以再增大一些，以便把更多的数据包发送出去；但只要网络出现拥塞，拥塞窗口的值就应该减小一些，以减少注入到网络中的数据包数。

若出现拥塞而不进行控制，整个网络的吞吐量将随输入负荷的增大而下降。

当然，我们有必要了解一下TCP协议两个比较重要的控制算法，一个是**流量控制**，另一个就是**阻塞控制**。

TCP协议通过滑动窗口来进行**流量控制**，它是控制发送方的发送速度从而使接受者来得及接收并处理。而拥塞控制是作用于网络，它是防止过多的包被发送到网络中，避免出现网络负载过大，网络拥塞的情况。

拥塞算法需要掌握其状态机和四种算法。拥塞控制状态机的状态有五种，分别是Open，Disorder，CWR，Recovery和Loss状态。四个算法为**慢启动**，**拥塞避免**，**拥塞发生时算法**和**快速恢复**。

**Congestion Control State Machine（拥塞控制状态机）**

![image-20200311161205794](/Users/ethancao/Library/Application Support/typora-user-images/image-20200311161205794.png)

1. Open状态

Open状态是拥塞控制状态机的默认状态。这种状态下，当ACK到达时，发送方根据拥塞窗口cwnd（Congestion Window）是小于还是大于慢启动阈值ssthresh（slow start threshold），来按照慢启动或者拥塞避免算法来调整拥塞窗口。

2. Disorder状态

当发送方检测DACK（重复确认）或者SACK（选择性确认）时，状态机将转变为Disorder状态。在此状态下，发送方遵循飞行（in-flight）包守恒原则，即一个新包只有在一个老包离开网络后才发送，也就是发送方收到老包的ACK后，才会发送一个新包。

3. CWR状态

发送方接收到一个拥塞通知时，并不会立刻减少拥塞窗口cwnd，而是每收到两个ACK就减少一个段，直到窗口的大小减半为止。当cwnd正在减小并且网络中没有重传包时，这个状态就叫CWR（Congestion Window Reduced, 拥塞窗口减少）状态。CWR状态可以转变成Recovery或者Loss状态。

4. Recovery状态

当发送方接收到足够（推荐为3个）的DACK（重复确认）后，进入该状态。该状态下，拥塞窗口cnwd每收到两个ACK就减少一个段（segment）直到cwnd等于慢启动值ssthresh，也就是刚进入Recover状态时cwnd的一半大小。发送方保持Recovery状态直到所有进入Recovery状态时正在发送的数据段都成功地被确认，然后发送方恢复成Open状态，重传超市有可能终端Recovery状态，进入Loss状态。

5. Loss状态

当一个RTO（重传超时时间）到期后，发送方进入Loss状态。所有正在发送的数据标记为丢失，拥塞窗口cwnd设置为一个段（segment），发送方再次以慢启动算法增大拥塞窗口cwnd。

Loss和Recovery状态的区别是：Loss状态下，拥塞窗口在发送方设置为一个段后增大，而Recovery状态下，拥塞窗口只能被减小。Loss状态不能被其他的状态中断，因此，发送方只有在所有的Loss开始时正在传输的数据都得到成功确认后，才能退到Open状态。

**四大算法**

拥塞控制主要是四大算法：

1. 慢启动
2. 拥塞避免
3. 拥塞发生
4. 快速回复

![image-20200311180224666](/Users/ethancao/Library/Application Support/typora-user-images/image-20200311180224666.png)

1. 慢启动算法（Slow Start）

所谓慢启动，也就是TCP连接刚建立，一点一点地提速，试探一下网络的承受能力，以免直接扰乱了网络通道的秩序。

2. 拥塞避免算法（Congestion Avoidance）

当拥塞窗口大小cwnd`>=`慢启动阈值ssthresh后，就进入拥塞避免算法。算法简述如下：

- 收到一个ACK，则cwnd = cwnd + 1/cwnd
- 每当过了一个往返延迟时间RTT，cwnd大小+1

过了慢启动阈值后，拥塞避免算法可以避免窗口增长过快导致窗口拥塞，而是缓慢的增加调整到网络的最佳值。

3. 拥塞状态时的算法

一般来说，TCP拥塞控制默认认为网络丢包是由于网络拥塞导致的，所以一般的TCP拥塞控制算法以丢包为网络进入拥塞状态的信号。对于丢包有两种判断方式：

- 超时重传RTO（Retransmission Timeout）超时
- 受到三个重复确认ACK

超时重传是TCP协议保证数据可靠性的一个重要机制，其原理是在发送一个数据以后就开启一个计时器，在一定时间内如果没有得到发送数据报的ACK报文，那么就重新发送数据，直到发送成功为止。

但是如果发送端接收到3个以上的重复ACK，TCP就意识到数据发生丢失，需要重传。这个机制不需要等到重传定时器超时，所以叫做**`快速重传`**，而快速重传后没有使用慢启动算法，而是拥塞避免算法，所以这又叫做快速恢复算法。

4. 快速恢复算法（Fast Recovery）

在进入快速恢复之前，cwnd和ssthresh已经被更改为原有cwnd的一般。快速恢复算法逻辑如下：

- `cwnd = cwnd + 3 * MSS`，加`3 * MSS`的原因是因为收到3个重复的ACK
- 重传DACKs指定的数据包
- 如果再收到DACKs，那么cwnd大小增加1
- 如果收到新的ACK，表明重传的包成功了，那么推出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法

![image-20200311194319310](/Users/ethancao/Library/Application Support/typora-user-images/image-20200311194319310.png)

如图所示，第五个包发生了丢失，所以导致接收方接收到三次重复ACK，也就是ACK5.所以将ssthresh设置当时cwnd的一半，也就是6/2 = 3，cwnd设置为 3 + 3 = 6.然后重传第5个包。当收到新的ACK时，也就是ACK11，则退出快速恢复阶段，将cwnd重新设置为当前的ssthresh，也就是3，然后进入拥塞避免算法阶段。

### 微服务和SOA

- 概念

**SOA（面向服务的架构）**：面向服务的架构（SOA）是一个组件模型，它将应用程序的不同功能单元（成为服务）通过这些服务之间定义良好的接口和契约联系起来。接口是采用的中立的方式进行定义的，它应该独立于实现服务的硬件平台、操作系统和编程语言。这使得构建在各种各样的系统中的服务可以以一种统一和通用的方式进行交互。

**微服务**：微服务架构是一种将单个应用程序作为一套小型服务开发的方法，每种应用程序都在自己的进程中运行，并与轻量级机制（通常是HTTP资源API）进行通信。这些服务是围绕业务功能构建的，可以通过全自动部署机制独立部署。这些服务的集中管理最少，可以用不同的编程语言编写，并使用不同的数据存储技术。

- 两者的区别

1. 微服务剔除SOA中复杂的ESB企业服务总线，所有的业务智能逻辑在服务内部处理，使用Http（Rest API）进行轻量化通讯
2. SOA强调按水平架构划分为：前、后端、数据库、测试等，微服务强调按垂直架构划分，按业务能力划分，每个服务完成一种特定的功能，服务即产品
3. SOA将组件以library的方式和应用部署在同一个进程中运行，微服务则是各个服务独立运行
4. 传统应用倾向于使用统一的技术平台来解决所有问题，微服务可以针对不同业务特征选择不同技术平台，去中心统一化，发挥各种技术平台的特长
5. SOA架构强调的是异构系统之间的通信和解耦合；（一种粗粒度、松耦合的服务架构）
6. 微服务架构强调的是系统按业务边界做细粒度的拆分和部署

- 微服务的技术难点

1. 服务治理，维护成本增加
2. 资源分配
3. 数据库分割带来数据冗余，保证数据一致性更为复杂
4. 负载均衡，每个微服务都得单独处理

### 谈谈Redis的使用，Redis的数据主从同步

这里要回头结合redis那本书，说一下源码中redis的一些处理策略。

**redis优势**

1. 性能极高：redis能读的速度是1100000次/s，写的速度是81000次/s
2. 丰富的数据类型：支持二进制strings，lists，hashes，sets及ordered sets
3. 原子：redis的所有操作都是原子性的，意思就是要成功执行要么失败完全不执行，单个操作是原子性的。多个操作也支持事务。
4. 丰富的特性：redis还支持publish/subscribe，通知，key过期，pipeline等实用特性

**主从同步**

redis的主从结构可以采用一主多从或者级联结构，redis主从复制可以根据是否全量分为全量同步和增量同步。

- 全量同步

redis全量赋值一般发生在slave初始化阶段，这时slave需要将master上的所有数据都复制一份。

1. 从服务器连接主服务器，发送sync命令
2. 主服务器接收到sync命令后，开始执行bgsave命令生成rdb文件并使用缓冲区记录此后执行的所有写命令
3. 主服务器bgsave执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令
4. 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照
5. 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令
6. 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令

完成上面几个步骤后就完成了从服务器数据初始化的所有操作，从服务器此时可以接收来自用户的读请求。

- 增量同步

redis增量复制是指slave初始化后正常开始工作时主服务器发生的写操作同步到从服务器过程。增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

- redis主从同步策略

主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave在任何时候都可以发起全量同步。redis策略是，无论如何首先会尝试进行增量同步，如果不成功，要求丛集进行全量同步。

- 注意点

如果多个slave断线，需要重启的时候，因为只要slave启动，就会发送sync请求和主机全量同步，当多个同时出现的时候，可能会导致master IO剧增宕机。

### C++一个空类

- 空类大小

1字节

- 实现方式

```c++
  1 #include<stdio.h>
  2 #include<iostream>
  3 
  4 class A {};
  5 class B {};
  6 class C: public A {
  7     virtual void fun() = 0;
  8 };
  9 
 10 class D: public B, public C {
 11     virtual void fund() = 0;
 12 };
 13 
 14 class E: public D {
 15     static int a;
 16 };
 17 
 18 using namespace std;
 19 int main(void) {
 20     cout << "sizeof(A)" << sizeof(A) << endl;
 21     cout << "sizeof(B)" << sizeof(B) << endl;
 22     cout << "sizeof(C)" << sizeof(C) << endl;
 23     cout << "sizeof(D)" << sizeof(D) << endl;
 24     cout << "sizeof(E)" << sizeof(E) << endl;
 25     return 0;
 26 }
```

```shell
sizeof(A)1
sizeof(B)1
sizeof(C)8
sizeof(D)8
sizeof(E)8
------------
```

实例化的原因（空类同样可以被实例化），每个势力在内存中都有一个独一无二的地址，为了达到这个目的，编译器往往会给一个空类银行的加上一个字节，这样空类在实例化之后在内存得到了独一无二的地址。多以A的大小为1.

而虚函数分配地址为一个指针地址，64位操作系统下为8字节。

总结来说：

1. 类的非静态成员数据的类型大小之和（静态成员被编译器放在一个global data members中）
2. 有编译器额外加入的成员变量的大小，用来支持语言的某些特性（如：指向虚函数的指针）
3. 为了优化存取效率，进行的边缘调整
4. 与类中的构造函数，析构函数以及其他的成员函数无关

- 空类默认有哪些函数

编译器会自动为你生成一个默认构造函数、一个默认拷贝构造函数、一个默认拷贝赋值操作符、一个默认析构函数。这些函数只有在第一次被调用时，才会被编译器所创建。所有这些函数都是inline和public的。



### 分布式缓存

**技术框架**

redis

memcached

**缓存的几种淘汰策略**

事实上不止是缓存，只要设计的内存，或者存储空间，所用到的策略和方法都是那几种，在操作系统里面的虚拟内存页面置换算法，有：最佳置换算法，FIFO、LRU、LFR、CNRU等等，和这里的缓存的淘汰策略如出一辙，只是在操作系统里是用来判定怎样替换更好。我个人的观点：所有涉及到存储空间里的内容清除，置换的，都是这些算法。

缓存淘汰策略用于决定缓存系统中哪些数据应该被删去。常见算法类型包括LFU、LRU、ARC、FIFO、MRU。

- 最不经常使用算法（LFU）

这个缓存算法使用一个计数器来记录条目被访问的频率。通过使用LFU缓存算法，最低访问数的条目首先被移除。这个方法并不经常使用，因为它无法对一个拥有最初高访问率之后长时间没有被访问的条目缓存负责。

- 自适应缓存替换算法（ARC）

在IBM AImaden研究中心开发，这个缓存算法同事跟踪记录LFU和LRU，以及驱逐缓存条目，来获得可用缓存的最佳使用。

- 先进先出算法（FIFO）

FIFO英文是First In First Out的缩写，是一种先进先出的数据缓存器，他与普通存储器的区别是没有外部读写地址线，这样使用起来非常简单，但缺点就是只能顺序写入数据，顺序的读出数据，其数据地址由内部读写指针自动+1完成，不能像普通存储器那样可以由地址线决定读取或写入某个指定地址。

- 最近最常使用算法（MRU）

这个缓存算法最先移除最近最常使用的条目。一个MRU算法擅长处理一个条目越久，越容易被访问的情况。

### Java内存缓存

Google Guava（一个java依赖）

```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>me.xueyao.cache</groupId>
    <artifactId>java-demo</artifactId>
    <version>1.0.0</version>

    <dependencies>
        <dependency>
            <groupId>javax.cache</groupId>
            <artifactId>cache-api</artifactId>
            <version>1.1.0</version>
        </dependency>

        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <version>27.0.1-jre</version>
        </dependency>
    </dependencies>
</project>
```



Guava是Google guava中的一个内存缓存模块，用于将数据缓存到JVM内存中。实际项目开发中经常将一些公共或者常用的数据缓存起来方便快速访问。

### 如何解决线上问题，步骤和解决办法（运维知识）

分为以下几个步骤：

1. 明确责任人，避免互相推诿
2. 治标，短期解决方案，紧急处理
3. 追根溯源，长期解决方案，避免再次出现
4. 举一反三，查找类似问题
5. 如何避免，防止开发新功能再次踩雷
6. 跟进人，有的问题处理时间较长，需要有个跟进人
7. 整理分享，最好过一段时间（一个月）整理近期发生的问题，进行分享

假如觉得以上步骤有点繁琐，简化版：

1. 评估影响范围
2. 试图重现问题
3. 临时方案和终极方案
4. 风险评估以及持续优化

遇到线上问题，恢复生产、降低损失是第一要务，修复bug是其次的。

软件工程师的核心竞争力是什么？本质就是一种**`解决问题的能力`**，一步步分析、解决和预防问题。

**日志分析**

线上bug，一般以查日志为主，所以前期的代码日志埋点很重要。当然后期的日志关键信息分析，也很重要。所以，搭建像ELK或Splunk这样的日志分析系统，方便日志查询。



### 除开gdb以外，有哪些服务端调试手段

- telnet可以调试端口是否正常

- ping可以查看是否丢包

- iostat可以查看磁盘是否超载

- tcpdump、wireshark可以查看TCP包

- 自研的监控平台可以查看机器历史状态

- top可以查看cpu和内存使用情况

- valgrind可以看内存，还有free

- trace -p可以查看
- dtruss/dtrace内核调用跟踪监视工具

- traceroute可以用查看路由路径，并且测算数据来回需要多久时间。

大部分情况下，我们会在linux主机系统下，直接执行命令：`traceroute hostname`

```shell
~/ » traceroute www.baidu.com                                                                               ethancao@EthanCaodeMacBook-Pro
traceroute: Warning: www.baidu.com has multiple addresses; using 14.215.177.39
traceroute to www.a.shifen.com (14.215.177.39), 64 hops max, 52 byte packets
 1  10.56.236.2 (10.56.236.2)  2.388 ms  2.221 ms  2.267 ms
 2  10.39.0.5 (10.39.0.5)  1.627 ms  1.573 ms  1.607 ms
 3  218.17.197.193 (218.17.197.193)  3.851 ms  3.185 ms  3.578 ms
 4  183.56.64.13 (183.56.64.13)  4.236 ms
    183.56.64.17 (183.56.64.17)  4.519 ms
    183.56.64.13 (183.56.64.13)  4.055 ms
 5  117.176.37.59.broad.dg.gd.dynamic.163data.com.cn (59.37.176.117)  4.726 ms
    125.176.37.59.broad.dg.gd.dynamic.163data.com.cn (59.37.176.125)  3.551 ms
    117.176.37.59.broad.dg.gd.dynamic.163data.com.cn (59.37.176.117)  3.643 ms
 6  202.105.106.37 (202.105.106.37)  5.607 ms
    119.145.47.77 (119.145.47.77)  4.626 ms *
 7  113.96.0.22 (113.96.0.22)  15.477 ms
    113.96.0.18 (113.96.0.18)  9.452 ms
    113.96.5.50 (113.96.5.50)  5.690 ms
 8  * 106.96.135.219.broad.fs.gd.dynamic.163data.com.cn (219.135.96.106)  9.215 ms  8.518 ms
 9  14.215.32.130 (14.215.32.130)  8.011 ms *  10.967 ms
10  * * *
11  * * *
```

**说明**

记录按序列号从1开始，每个纪录就是一跳 ，每跳表示一个网关，我们看到每行有三个时间，单位是 ms，其实就是-q的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 traceroute -q 4 www.58.com ，表示向每个网关发送4个数据包。

有时我们traceroute 一台主机时，会看到有一些行是以星号表示的。出现这样的情况，可能是防火墙封掉了ICMP的返回信息，所以我们得不到什么相关的数据包返回数据。

有时我们在某一网关处延时比较长，有可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台DNS出现问题时，不能解析主机名、域名时，也会 有延时长的现象；您可以加-n 参数来避免DNS解析，以IP格式输出数据。

如果在局域网中的不同网段之间，我们可以通过traceroute 来排查问题所在，是主机的问题还是网关的问题。如果我们通过远程来访问某台服务器遇到问题时，我们用到traceroute 追踪数据包所经过的网关，提交IDC服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，就是我们发现问题所在，IDC服务商也不可能帮助我们解决。



- Hash索引的实现原理
- Mysql的Innodb和MyIsam两种引擎的区别
- Mysql数据库索引的实现原理
- 一台机器只有1G物理内存，是否程序可以获取到2G，为什么？
- 操作系统虚拟内存是如何实现的
- Vector扩容的原理
- 什么缓解会发送RST包（TCP时序图）
- 垃圾回收、Redis、异常错误捕获、消息队列、kafka日志框架
- 秒杀系统怎么设计，性能优化（网站反应很慢，怎么优化）
- 怎么保证分布式数据的一致性，项目经验
- Redis数据结构、持久化方式和高峰期如何避免雪崩、主从同步
- 唯一索引和key索引。Http协议相关，如何实现一个hash数据结构
- IO模型
- TCP粘包问题
- web漏洞
- http2.0有哪些特性
- IO复用select、poll、epoll区别
- ES、ZK、ETDC、kafka了解

### MQ丢失消息怎么处理，有没有机制保证

### kafka和rabbitmq的区别

- 在应用场景方面

**RabbitMQ**

RabbitMQ遵循AMQP协议，由内在高并发的erlang语言开发，用在实时的对可靠性要求比较高的消息传递上，适合企业级的消息发送订阅，也是比较受到大家欢迎的。

**kafka**

kafka是Linkedin于2010年12月份开源的消息发布订阅系统，它主要用于处理活跃的流式数据，大数据量的数据处理上，常用日志采集，数据采集上。

**ActiveMQ**

1. 异步调用
2. 一对多通信
3. 做多个系统的继承，同构、异构
4. 作为RPC的替代
5. 多个应用相互解耦
6. 作为事件驱动架构的幕后支撑
7. 为了提高系统的可伸缩性

- 在架构模型方面

**RabbitMQ**

遵循AMQP协议，RabbitMQ的broker由Exchange，Binding，queue组成，其中exchange和binding组成了消息的路由键；客户端Producer通过连接channel和server进行通信，Consumer从queue获取消息进行消费（长连接，queue有消息会推送到consumer端，comsumer循环从输入流读取数据）。rabbitMQ以broker为中心；有消息的确认机制。

**kafka**

kafka遵从一般的MQ结构，producer，broker，consumer，以consumer为中心，消息的消费信息保存在客户端consumer上，consumer根据消费的点，从broker上批量pull数据；无消息确认机制。

- 吞吐量

kafka具有高吞吐量，内部采用消息的批量处理，zero-copy机制，数据的存储和获取是本地磁盘顺序批量操作，具有O(1)的复杂度，消息处理的效率很高。

rabbitmq在吞吐量方面稍逊于kafka，他们的出发点不一样，rabbitmq支持对消息的可靠的传递，支持事务，不支持批量操作；基于存储的可靠性要求可以采用内存或者硬盘。

- 可用性

rabbitmq支持mirror的queue，主queue失效，mirror queue接管。

kafka的broker支持主备模式

- 在集群负载均衡方面

kafka采用zookeeper对集群中的broker、consumer进行管理，可以注册topic到zookeeper上；通过zookeeper的协调机制，producer保存对应topic的broker信息，可以随机或者轮询发送到broker上；并且producer可以基于语义指定分片，消息发送到broker的某分片上。

rabbitmq的负载均衡需要单独的loadbalancer进行支持。



### MQ消息乱序怎么办

- 分布式锁怎么做？
- 负载均衡怎么做？
- TCP、项目，解决过的难点问题，思路过程
- 同步异步
- 进程线程

### Redis扩容和缩容

### Redis如何处理限频

- 分布式架构，拿Nginx来讲的
- 进程间通信
- zookeeper、kafka的知识，日志处理的架构，分布式系统的基本要素啥的

### ThreadLocal用来干啥的，底层实现原理

threadlocal使用方法很简单：

```java
static final ThreadLocal<T> sThreadLocal = new ThreadLocal<T>();
sThreadLocal.set()
sThreadLocal.get()
```

threadlocal而是一个县城内部的存储类，可以在指定线程内部存储数据，数据存储以后，只有指定线程可以得到存储数据。

多线程访问同一个共享变量的时候容易出现并发问题，特别是多个线程对一个变量进行写入的时候，为了保证线程安全，一般使用者在访问共享变量的时候需要进行额外的同步措施才能保证线程安全性。ThreadLocal是除了加锁这种同步方式之外的一种保证，一种规避多线程访问出现线程不安全的方法，当我们在创建一个变量后，如果每个线程对其进行访问的时候访问的都是线程自己的变量，这样就不会存在编程不安全的问题。

ThreadLocal是JDK包提供的，它提供线程本地变量，如果创建一个Treadlocal变量，那么访问这个变量的每个线程都会有这个变量的副本，在实际多线程操作的时候，操作的是自己本地内存中的变量，从而规避了线程安全问题。

ThreadLocal类结果及方法解析

![image-20200313115550652](/Users/ethancao/Library/Application Support/typora-user-images/image-20200313115550652.png)

上图可知：`ThreadLocal`三个方法get、set、remove以及内部类ThreadLocalMap

**值得注意的是，python也有ThreadLocal使用方式，不仅Java有**

ThreadLocal是如何做到为每一个线程维护变量的副本的呢？其实实现的思路很简单：在ThreadLocal类中有一个Map，用于存储每一个线程的变量副本，Map中元素的键为线程对象，而值对应线程的变量副本。

> ThreadLocalMap<threadObject, threadValCopy>对象保存了对应关系

### AUC如何计算

Are under curve是一个模型评价指标，用于分类任务。那么这个指标代表什么呢？这个指标项表达的含义，简单来说其实就是随机抽出一对样本（一个正样本，一个负样本），然后用训练得到的分类器来对这两个样本进行预测，预测得到正样本的概率大于负样本概率的概率。

> AUC = P(P<sub>正样本</sub> > P<sub>负样本</sub>)

其他用于衡量机器学习的指标：

> 召回率（Recall）、准确率（Precision）、F1值等

计算AUC通常是由机器或者库完成，当然，为了更好的理解AUC，这里简述一个例子，计算AUC：

在有M个正样本，N个负样本的数据集里面。一共有M\*N对样本（一对样本集，一个正样本与一个负样本）。统计这M\*N对样本里正样本的预测概率大于负样本的预测概率的个数。
$$
I(P_{正样本}, P_{负样本}) = 
\begin{cases}
1, & {P_{正样本} > P_{负样本}} \\
0.5, & {P_{正样本} = P_{负样本}} \\
0, & {P_{正样本} < P_{负样本}}
\end{cases}
$$

| ID   | label | pro  |
| ---- | :---: | :--: |
| A    |   0   | 0.1  |
| B    |   0   | 0.4  |
| C    |   1   | 0.35 |
| D    |   1   | 0.8  |

如表所示，有4条样本。2个正样本，2个负样本，那么M\*N=4。即总共有4个样本对。分别是：

> (D, B), (D, A), (C, B), (C, A)

比如：（D, B），正样本D预测的概率大于负样本B预测的概率（也就是D的得分比B高），记为1

同理，（C, B），正样本C预测概率小于负样本C预测概率，记为0
$$
\left(\frac{1+1+1+0}{4}\right) = 0.75
$$
最后可以算得，总共3个符合正样本得分高于负样本得分，故最后的AUC为0.75.



### wide和deep之间的区别

推荐系统在电商等平台使用广泛，这里讨论wide&deep推荐模型，初始是由google推出的，主要用于app的推荐。

- 概念理解

wide&deep模型，旨在使得训练得到的模型能够同时获得记忆（memorization）和泛化（generalization）能力：

记忆（memorization）即从历史数据中发现item或者特征之间的相关性。

泛化（generalization）即相关性的传递，发现在历史数据中很少或者没有出现的新的特征组合。

具体到模型定义角度，wide是指广义线性模型（Wide Linear Model），deep是指深度神经网络（Deep Netural Network）。

两者区别：

Memorization趋向于更加保守，推荐用户之前有过的items。相比之下，generalization更加趋向于提高推荐系统的多样性（diversity）。

Wide & Deep包括两部分：线性模型(LR逻辑回归)+DNN（深度神经网络）部分。结合上面两者的优点，平衡memorization和generalization。

- 讲讲历史

wide & deep是google提出来的，提出时间是2016年，算起来这个算法还比较新了，附带论文《Wide & Deep Learning for Recommender Systems》，链接：https://arxiv.org/pdf/1606.07792.pdf，这个算法在谷歌应用商店做排序。

另外一个是DeepFm，来自于2017年华为提出来的《DeepFM：A Factorization-Machine based Neural Network for CTR Prediction》，链接：https://arxiv.org/pdf/1703.04247.pdf，这个华为用在应用商店做排序的。

以上者两个算法即可以在广告中做CTR预估，也可以在推荐系统中做排序。

此外，阿里巴巴2018年发布了Graph Embedding（GE），附带论文《Billion-scale Commondity Embedding for E-commerce Recommendation in Alibaba》，链接：https://arxiv.org/pdf/1803.02349.pdf，这个是用在淘宝的推荐系统中。

### Joint Training和Ensemble

joint training和ensemble是有区别的，ensemble里训练时模型互不影响，只是在预测时一起作用，joint training在训练时模型一起训练。

### 广告和推荐算法工程实现

**注意点**

1. 将广告和推荐算法与工程后台框架在业务上要解耦合，比如定向，预估都会不可避免的出现算法调优涉及到需要改动框架代码的尴尬境地。
2. 如果涉及到微服务时效性（模块超时）问题，假如独立出来服务，要考虑多个业务（子微服务）提供服务时，主进程等待子模块返回这个操作是多线程并发，并且支持异步。
3. 考虑对不同的服务做qps和响应时间的划分，对时效性低的要和时效性高的区别对待。

### 问LR为什么不能用MSE

顺便写一些LR的损失函数

### 神经网络优化器

我们知道，神经网络的学习的目的就是寻找适合的参数，使得损失函数的值尽可能小。解决这个问题的过程被称为**最优化**。解决这个问题使用的算法叫做**优化器**。

- SGD

**随机梯度下降法（Stachastic gradient desent）**：SGD的想法即使沿着梯度的方向前进一定距离。

SGD的优点是简单，容易实现。但是其缺点就是低效，因为有的时候梯度的方向并没有指向最小值的方向。低效的原因有两大方面：

1. 函数呈延伸状态，梯度指向了“谷底”。这使得损失函数值不停的在震荡。
2. 梯度方向指向了极小值。因为所有维度的梯度在这附近都接近于0，这使得损失函数在这里变化的很慢。

改进办法：引入**`Momentum`**

实际上震荡是不可避免的，我们只能考虑减轻震荡。**使得梯度方向不变的维度上速度变快，梯度方向有所改变的维度上的更新速度变慢，这样就可以加快收敛并减小震荡**。

- AdaGrad

这种方法主要是为了解决SGD遇到鞍点或者极小值点后学习变慢的问题。

在神经网络中有一种方法经常被使用：学习率衰减方法（Learning rate decay），也就是说随着学习的进行，使学习率逐渐减少。AdaGrade进一步发展了这个想法，他会为参数的每一个元素适当的调整学习率。

AdaGrad的优点是可以动态的调整学习率

缺点是AdaGrad会记录过去所有的梯度平方和，最后有可能不再更新。针对这个问题有一个方法叫做RMSProp进行了优化。

- Adam

Adam直观的来讲就是融合了Mementum和AdaGrad方法。

### 机器学习方法论

最宝贵的经验不是书上或者论文中明白写出来的：

1. 问题是什么？
2. 用什么指标来度量？
3. 问题的复杂度是什么量级？
4. 模型不好，本质上就是**`模型复杂度没有匹配问题负载`**，哪里是模型复杂度的瓶颈？

- 标注数据
- 人的智慧，创造有价值的特征，还是说可以用深度学习来创造feature？
- 海量用户行为数据
- 模型的调整，过于简单的模型，相当于强行约束了复杂度的上限，使得明明有海量的数据硬是用不上

5. 找不到便利的数据和特征，就可以想想是否能把问题分解成子问题，也许在子问题空间下，你能想到更好的特征、数据和模型。同事分解了问题，就能够引入更多的人员来并行工作
6. 知道怎么做干净的实验，系统性的探索所有的可能性，排除无关因素

在所有的经验中，狭义的模型和特征工程只是`第4点`的一部分而已。

但是剩余的部分也都是技术（与具体的应用领域无关），是建立在读机器学习的能力与界限有清楚认识的基础上的一些抽象。



### web server大文件上传下载

webserver+sftp？目测不行

有一个一般解决思路：

1. 大文件上传时进行分片
2. 分片上传
3. 在服务端对分片文件进行合并

具体实现上：

1. 全端做数据分片，推荐百度的WebUploader来实现
2. 对于文件合并，前端在分片之后，在请求服务端合并的时候，请求中要带上分片序号和大小，服务器按照请求数据中给的分片序号和每片分块大小算出开始位置。与读取到的文件片段数据，写入文件即可。这里合并后的文件会存储两个路径，一个是当前网盘目录下的路径，一个是真实的永久路径（目的是为了实现秒传的功能）。
3. 对于**`秒传`**这个功能的实现，其实原理技术检验文件MD5，在一个文件上传前先获取文件内容MD5值或者部分取值MD5。然后查找自己的记录是否已存在相同的MD5，如果存在就直接从服务器真是路径取，而不需要重新进行分片上传了，从而达到秒传的效果。



### 用sed替换某一行的某个词

这里介绍一个比较常见的用法，文本内容如下：

```shell
文本内容如下:
aaa bbb ccc 111 222 abc
eee fff ggg 111 222 efg
111 222
aaa ccc ddd 111 222 acd

需求:
在有aaa的行中，将 111 替换为 AAA，将 222 替换为 BBB
即，输出结果为：
aaa bbb ccc AAA BBB abc
eee fff ggg 111 222 efg
111 222
aaa ccc ddd AAA BBB acd
```

方法如下：

```shell
sed -i '/aaa/ { s/111/AAA/g;  s/222/BBB/g; }'  filename
```

更改一下，需要在字符串`AAA`所在的行，头尾各添加相应字符串：

```shell
sed -i '/AAA/ {s/^/HEAD&/g; s/$/&TAIL/g;}' filename
```



### kill命令的作用/选项解释

本质上来讲，kill命令指示用来向进程发送一个信号，至于这是什么信号，是用户指定的。

也就是说，kill会向操作系统内核发送一个信号（多是终止信号）和目标进程的PID，然后系统内核根据收到的信号类型，对指定进程进行相应的操作。

常用的信号列表：

| 信号编号 | 信号名 | 含义                                                         |
| :------: | ------ | ------------------------------------------------------------ |
|    0     | EXIT   | 程序退出时收到该信号                                         |
|    1     | HUP    | 挂掉电话线或中断连接的挂起信号，这个信号也会造成某些进程在没有终止的情况下重新初始化 |
|    2     | INT    | 表示结束进程，但并不是强制性的，常用的“Ctrl+C”组合键发出就是一个kill -2的信号 |
|    3     | QUIT   | 退出                                                         |
|    9     | KILL   | 杀死进程，即强制结束进程                                     |
|    11    | SEGV   | 段错误                                                       |
|    15    | TERM   | 正常结束进程，是kill命令的默认信号                           |
|    -1    |        | 让进程重启                                                   |
|   -19    |        | 让进程暂停                                                   |



### 客户端频控

10秒频控，在10秒发起10万个请求，在第11秒发起10万请求，这样我就在2秒内发起了20w个请求，你如何解决？

```shell
（降低时间窗口期，10秒的窗口期换成2秒）
```

服务端频率控制方法：

参考DSP的频率控制，使用用户设备的MAC地址、uuid、muid（用户设备md5）在redis里面做最近一次访问的时间戳保存，服务端每次都检查用户是否需要被频率控制。

频率控制一方面是为了降低服务器的处理负担，另外一方面是减少重复特征，为模型训练提供有效素材。频率控制做的不好，或者缺乏服务端频率控制，很有可能会造成日志数据被“清洗”的悲剧。

### 如何做分库访问db

基本思想就是把一个数据库切分成多个部分放在不同的Server上，从而缓解单一数据库的性能问题。**这个有点类似redis的分布式部署，hash散列**。不太严格的讲，对于海量数据的数据库，如果是因为表多而数据不多，这个时候适合使用垂直切分，即把关系紧密（比如同一个模块）的表切分出来放在一个server上。如果表并不多，但是每张表的数据非常多，这个时候适合水平切分，即把表的数据按照某种规则（比如按ID散列）切分到多个server上。当然，现实中更多的是两种情况混杂到一起，这时候需要根据实际情况作出选择，也可能会综合使用垂直与水平切分，从而将原有数据库切分成类似矩阵一样可以无限扩充的server阵列。

**垂直切分**

垂直切分最大的特点就是规则简单，实施也更为方便，尤其适合各业务之间的耦合度非常低，相互影响很小，业务逻辑非常清晰的系统。在这种系统中，可以很容易做到将不同业务模块所使用的表分拆到不同的数据库中。根据不同的表来进行拆分，对应用程序的影响也更小，拆分规则也会比较简单清晰。

**水平切分**

水平切分与垂直切分相比，相对来说稍微复杂一些。因为要将同一个表中的不同数据拆分到不同的数据库中，对于应用程序来说，拆分规则本身就较垂直拆分更为复杂，后期的数据维护也会更为复杂一些。

### 主键/外键/索引

**定义**

主键：唯一标识一条记录，不能有重复的，不允许空

外键：表的外键是另一个表的主键，外键可以有重复的，可以是空值

索引： 该字段没有重复值，但可以有一个空值

**作用**

主键： 用来保证数据完整性

外键： 用来和其他表建立联系用的

索引： 是提高查询排序的速度

**个数**

主键：主键只能有一个

外键：一个表可以有多个外键

索引：一个表可以有多个唯一索引

总体来说，SQL的主键和外键就是起约束作用。例如：外键更新时，不能改为主键中没有的值

**IO次数**

- 走主键一次io
- 走联合索引 两次io
- 不走索引 多次io



### 在32gb的内存里对1TB数据排序



### hadoop和hive

**hadoop和hive关系**

hive是hadoop的延伸

hadoop是一个分布式的软件处理框架，hive是一个提供了查询功能的数据仓库，最核心的就是hadoop提供了FS（file system）抽象，能够支持hive进行数据存储。那计算机类比，hadoop就是文件系统，而hive就是mysql的应用程序。

**hive的udf是什么**

udf（User Define Function）用户自定义函数，写过flink udf的同学都知道，是一个意思，就是基于scala或者java写了一些扩展插件，用户可以在hive里面使用扩展程序掉用这些jar插件，以执行一些自定义的操作。

**一张大表和一张小表join（数据倾斜）**

Hive不能把过于大型的数据集合从RDD转成collect，collect是放到本机内存，会导致内存超限，应该在最终结果获取环节使用collect。

总体来说有两种解决方案：

1. 普通的join，将**小表放在前面**，效率会高。hive会将小表进行缓存。
2. 使用MapJoin。

`MapJoin`可以解决**`数据倾斜`**问题。

基本原理是：在小数据量的情况下，SQL会将用户指定的小表全部加载到执行Join操作的程序的内存中，从而加快Join的执行速度。而且执行map操作的时候，逐一和大表匹配，省去了reduce操作。

```mssql
select /*+MAPJOIN(b)*/ a.a1,a.a2,b.b2 from tablea a JOIN tableb b ON a.a1=b.b1
```

MapJoin的join发生在map阶段，普通join的join发生在reduce阶段，mapjoin可以提高效率。

使用MAPJOIN时，需要注意：

```shell
LEFT OUTER JOIN的左表必须是大表；
RIGHT OUTER JOIN的右表必须是大表；
INNER JOIN左表或右表均可以作为大表；
FULL OUTER JOIN不能使用MAPJOIN；
MAPJOIN支持小表为子查询；
使用MAPJOIN时需要引用小表或是子查询时，需要引用别名；
在MAPJOIN中，可以使用不等值连接或者使用OR连接多个条件；
目前ODPS在MAPJOIN中最多支持指定6张小表，否则报语法错误；
如果使用MAPJOIN，则所有小表占用的内存总和不得超过512M（解压后的逻辑数据量）。
```

### 集中常见排序算法时间复杂度

(1)冒泡排序：

是相邻元素之间的比较和交换，两重循环O(n2)；所以，如果两个相邻元素相等，是不会交换的。所以它是一种稳定的排序方法

(2)选择排序：

每个元素都与第一个元素相比，产生交换，两重循环O(n2)；举个栗子，5 8 5 2 9，第一遍之后，2会与5交换，那么原序列中两个5的顺序就被破坏了。所以不是稳定的排序算法

(3)插入排序：

插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。刚开始这个小序列只包含第一个元素，事件复杂度O(n2)。比较是从这个小序列的末尾开始的。想要插入的元素和小序列的最大者开始比起，如果比它大则直接插在其后面，否则一直往前找它该插入的位置。如果遇见了一个和插入元素相等的，则把插入元素放在这个相等元素的后面。所以相等元素间的顺序没有改变，是稳定的。

(4)快速排序
  快速排序有两个方向，左边的i下标一直往右走，当a[i] <= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] > a[center_index]。如果i和j都走不动了，i <= j, 交换a[i]和a[j],重复上面的过程，直到i>j。 交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为 5 3 3 4 3 8 9 10 11， 现在中枢元素5和3(第5个元素，下标从1开始计)交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j]交换的时刻。时间复杂度 O(nlogn)。

(5)归并排序
  归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个序列(1次比较和交换),然后把各个有序的段序列合并成一个有序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定性。那么，在短的有序序列合并的过程中，稳定是是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。

(6)基数排序
  基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。

(7)希尔排序(shell)
  希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小，插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。

(8)堆排序
  我们知道堆的结构是节点i的孩子为2*i和2*i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n的序列，堆排序的过程是从第n/2开始和其子节点共3个值选择最大(大顶堆)或者最小(小顶堆),这3个元素之间的选择当然不会破坏稳定性。但当为n/2-1, n/2-2, ...1这些个父节点选择元素时，就会破坏稳定性。有可能第n/2个父节点交换把后面一个元素交换过去了，而第n/2-1个父节点把后面一个相同的元素没有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法

### C++依赖注入（IOC）

依赖注入主要的用途，我个人理解为两点：

1. 类似java的“反射”
2. 方便后期扩展

依赖注入大概有三种方式：

- 构造器注入

将被一拉对象通过构造函数的参数注入给依赖对象，并且在初始化对象的时候注入。

优点：对象初始化完成后便可获得可使用的对象。

缺点：

1. 当需要注入的对象很多的时候，构造器的参数列表将会很长
2. 不够灵活。若有多种注入方式，每种方式只需注入指定几个依赖，哪儿就需要提供多个重载的构造函数，麻烦。

- setter方法注入

IOC Service Provider通过调用成员变量提供的setter函数将被依赖对象注入给依赖类。

优点：可以选择性地注入需要的对象

缺点：依赖对象初始化完成后由尚未注入被依赖对象，因此还不能使用。

- 接口注入

依赖类必须要实现指定的接口，然后实现该接口中的一个函数，该函数就是用于依赖注入。该函数的参数就是要注入的对象。

优点：接口注入中，接口的名字、函数的名字都不重要，主要保证函数的参数是要注入的对象类型即可。

缺点：侵入行太强，不建议使用。

PS：什么是侵入行？

如果类A要使用别人提供的一个功能，若为了使用这功能，需要在自己的类中增加额外的代码，这就是侵入性。

- 基于注解

基于Java的注解功能，在私有变量前加"@Autowired"等注解，不需要显式定义以上三种代码，便可以让外部容器传入对应的对象。该方案相当于定义了一个public的set方法，但是因为没有真正的set方法，从而不会为了实现依赖注入导致暴露了不该暴露的接口（因为set方法只想让容器访问来注入而不希望其他依赖此类的对象访问）。

下面举一个例子来帮助我们理解C++伪代码的依赖注入：

```c++
// 当伪码用，不用关注语法
class IB {}
class B1 : public IB{}
class B2 : public IB{}

struct A {
    A(IB *b) {}
}

// 一般处理
A *a1 = new A(new B1);
A *a2 = new A(new B2);

// 用工厂模式，A不想依赖IB的具体实现
// 省略工厂代码
A *a1 = new A(Factory::create("B1"))
A *a2 = new A(Factory::create("B2"))

// A需要依赖工厂类，工厂类以来IB的具体实现B1/B2
// 试试依赖注入容器怎么搞(API随便写的，各个容器库不一样)
IOCContainer ioc;
ioc.bind<A, B1>("B1");
ioc.bind<A, B2>("B2");

A *a1 = ioc.resolve<A>("B1")
```





- Cassandra是如何存储的？为什么不用mysql？二者的区别。
- Elastic search如何存储，如何查询，其中做了什么优化？什么是倒排索引？
- 数据库、mysql和postgre的事务是如何实现的。
- postgre和mysql数据库的区别是什么
- 32位的系统最多可以new出多大的内存？
- 32位的系统，最多可以创建多少的线程？
- 什么进程kill -9 杀不掉（处于D状态的进程杀不掉）
- 跨国的专线（高时延，大带宽）的TCP通讯如何优化？
- 设置一个合理的发送和接收缓冲区（带宽时延乘积）
- 调大初始拥塞控制窗口大小
- 挑战一致性hash扩容过程，配额服务扩容如何作到平滑，对业务不影响，或者业务不感知
- 进程间通讯有哪些机制？哪种速度最快？为什么？
- cap定理、base理论、Redis集群

### redis扩容、缩容

- 扩容（先主后从）

1. 先复制`redis.conf`文件，修改端口
2. 启动新的redis（同时启动主从节点）
3. 使用`redis-trib.rb`（官方工具）add-node添加主节点到cluster
4. 为主节点分配slots，redis内存重新分片（数据不丢失），使用`reshard`
5. 然后再是从节点，进入从节点的命令行，执行`cluster replicate`同步主节点

- 缩容（先从后主）

1. 使用`redis-trib.rb`执行del-node删除从节点，这里就到此为止了
2. 对于主节点，先使用`reshard`命令迁移slots数据插槽到其他不需要删除的主节点
3. 然后再使用del-node删除主节点

### TCP TIME_WAIT

- 什么情况出现timewait

当我们主动关闭一个socket链接的时候，尽管持有这个socket的进程已经关闭，但是这个socket（文件）还处于一个TIME_WAIT状态（客户端），再次启动这个进程是无法再去bind这socket，直到这个socket从TIME_WAIT转移到CLOSED状态。简而言之，客户端主动断开连接，客户端TIME_WAIT。

- 主要作用（为什么我们需要）

首先TIME_WAIT一定是从FIN_WAIT_2转移过来的。进入TIME_WAIT意味着这个tcp socket在主动关闭的时候，自己的FIN已经被对方确认，而且对方也发了一个FIN过来表示对方也没有什么数据要主动传输了。

因此，处于TIME_WAIT等待这么久时间，首先第一个作用：对方FIN的ACK确认（我们发的）有可能在传输过程中被丢弃。于是对方会重新发送FIN（简单来说，对方不知道我们已经知道他们不发数据了），停留在TIME_WAIT可以对重传的FIN进行确认。否则，对方将一直处于LAST_ACK状态。

第二个作用，等待较长时间，让在这个socket连接上传输的数据能够从整个网络中清空出去。（TCP超时重传导致数据包还在飞，对方会误认为我们还在传数据，直到收到ACK）



## 编程部分

### N个人中至少两个人同一天生日的概率

首先我们要看这个n多大，假如n=366，那么假设全年365天，就算前面365个人的生日都不重复，那么第366个人的生日一定与前面365个人的生日当中的其中一个重复。所以当n>=366，概率为1

再回头来看一下人数n在365这个范围以内的情况

我们先把这个问题换成一个反向问题，那么至少有两个人同一天生日的反面问题是：完全没有相同一天生日的概率。这个概率记做P(0)，没有人与第一个人同一天生日

那么全概率: 1 = P(0) + P(A)

其中，P（A）为至少有两个人是同一天生日的概率，P（A） = P（1）+ P(2) +... + P(N-1)

其中P（1）表示1个人与其他人同一天生日，P（N-1）表示有N-1个人与剩下来的人同一天生日

所以：P（A）就是我们要求的目标概率：P(A) = 1 - P（0），这个问题就变成了求没有人和其他人同一天生日的问题。

那么，第一个人的生日是随机的：365 / 365

第二个人, 364 / 365

....

第N个人，365 - (n-1) / 365

把他们的概率乘积起来，那么就是其全不相同的概率：

P(0) = (365 / 365) * (364 / 365) * .... * (365 - n + 1) / 365

= (365 * 364 * .... * 1 * 0 * ....* (365 - n + 1)  )/ 365^n

所以可以看出来，当n >= 366时

p(0) = 0，这也验证了之前我们讨论的观点

当n < 365时

比如n = 2

P(A) = 1 - (365 * 364) / 365 ^ 2

= 1- 0.997

= 0.003

以此类推，当到达45个人时，概率达到0.99

代码实现：

```c++
  1 #include <iostream>
  2 
  3 using namespace std;
  4 double calc_nobody_same_pro(int n){
  5     double p_n_same = 0.0;
  6     if (n >= 366) {
  7         cout << "输入人数超过366" << endl;
  8         p_n_same = 0.0;
  9     } else if (n <= 1) {
 10         cout << "输入人数不足2个" << endl;
 11         p_n_same = 1.0;
 12     } else {
 13         p_n_same = 1.0;
 14         while (n > 0){
 15             p_n_same *= ((double)(365 - n + 1) / (double)365);
 16             // cout << "计算第" << n << "个人之后的概率为: " << p_n_same << endl;
 17             n--;
 18         }
 19     }
 20 
 21     return p_n_same;
 22 }
 23 
 24 double least_2_same_birth_pro(int n) {
 25     double nobody_birth_same = calc_nobody_same_pro(n);
 26     cout << "没有人同一天生日的概率为: " << nobody_birth_same << endl;
 27     return 1 - nobody_birth_same;
 28 }
 29 
 30 
 31 int main(int argc, char* argv[]) {
 32     int count = atoi(argv[1]);
 33     cout << "输入人数为: " << count << endl;
 34     double p = least_2_same_birth_pro(count);
 35     cout << "至少2个人同一天生日的概率为: " << p << endl;
 36     return 0;
 37 }
"same_birthday.cpp" 37L, 1038C
```

### 整数数组中找出前边的数都比自己小，后边的数都比自己大的数

比如整数数组[2，3，10，5，8，11，7，4，9，18，19 ]

思路上来说，就是将数组分为两半，所以，考虑使用2分查找的思路解决问题

首先，最简单的思路：

从左边开始遍历，找出左边最大的数，并且找出右边最小的数，跟当前数比较。

左边最大的数记为left_biggest

右边最小的数记为right_least

当前数记为now

如果，left_biggest < now < right_least，那么now这个数就是我们想要的。反之，

如果，left_biggest > now 说明左边存在比当前数更大的，说明，当前位置不合适，起码left_biggest都比自己大了，说明当前位置并不是最佳位置。那么接下来判断，

如果，right_least是否比left_biggest更大，假如成立，那么可以认为，now右边的数，都比左边大。那么，当前位置只是不满足左边都比自己小，往右找一个数比左边最大数都大的数就可以了。

例子中：

第一个数3，左边最大数2， 右边最小数4， 比较看来，右边最小数，比左边最大数大，并且比3大，说明符合要求。

代码实现如下。

```c++
#include <iostream>
#include <stdlib.h>

using namespace std;

// 返回0表示没有比自己大的数,大于0表示该数的数值，且pos表示数在数组中的偏移量
// type = 0 表示求最小值
// type = 1 表示求最大值
void find_most_number(int type, int* sub_array, int count, int& most_number, int& most_pos) {
    most_pos = 0;
    most_number = sub_array[0];
    for (int i = 0; i < count; i++) {
        if (type == 0) {
            if (sub_array[i] < most_number) {
                most_number = sub_array[i];
                most_pos = i;
            }
        } else if (type == 1) {
            if (sub_array[i] > most_number) {
                most_number = sub_array[i];
                most_pos = i;
            }
        } else {
            break;
        }
    }
    return;
}

#define MAX 1
#define MIN 0
// 遍历原始数组，找出所有的数
void find_mid_number(int* input_array, int count) {
    int now_pos = 1;
    if (count < 3) {
        cout << "输入数组长度小于3，不处理" << endl;
    }
    for (; now_pos < count - 1 && now_pos > 0; ) {
        int left_biggest = 0;
        int right_least = 0;
        int l_b_pos = 0;
        int r_l_pos = 0;
        int now = input_array[now_pos];
        // 找出左边最大值
        find_most_number(MAX, input_array, now_pos, left_biggest, l_b_pos);
        // 找出右边最小值
        find_most_number(MIN, input_array + now_pos + 1, count - now_pos - 1, right_least, r_l_pos);
        r_l_pos = now_pos + r_l_pos + 1;
        cout << "当前位置[" << now_pos << ":" << now << "]," << \
            "左边最大值为[" << l_b_pos << ":" << left_biggest << "]," << \
            "右边最小值为[" << r_l_pos << ":" << right_least << "]" << endl;
        if (left_biggest < now && right_least > now) {
            cout << "当前值[" << now_pos << ":" << now << "]符合目标要求" << endl;
            now_pos += 1;
            cout << "跳转到[" << now_pos << ":" << input_array[now_pos] << "]" << endl;
        } else if (now > right_least) {
            cout << "当前值[" << now_pos << ":" << now << "]右边存在比自己小的值[" << r_l_pos << ":" << right_least << "]" << endl;
            now_pos += 1;
            cout << "跳转到[" << now_pos << ":" << input_array[now_pos] << "]" << endl;
            
        } else if (now < left_biggest) {
            cout << "当前值[" << now_pos << ":" << now << "]左边存在比自己大的值[" << l_b_pos << ":" << left_biggest << "]" << endl;
            now_pos += 1;
            cout << "跳转到[" << now_pos << ":" << input_array[now_pos] << "]" << endl;
        }
    }
    return;
}

int main(int argc, char* argv[]) {
    int number_count = argc - 1;
    cout << "输入了一个长度为: " << number_count << " 的数组" << endl;
    cout << "数组内容为: [ ";
    int* input_array = (int*)malloc(sizeof(int) * number_count);
    for (int i = 1; i < argc; i++) {
        int number = atoi(argv[i]);
        input_array[i - 1] = number;
        cout << number << " ";
    }
    cout << "]" << endl;
    find_mid_number(input_array, number_count);

    free(input_array);
}
```



### 字符串去空格

比方说一个字符串：“ 1 2 3 4 5 6”

要去除空格，一般来说会要求我们不开辟其他内存空间去做这个事情。

遇到第一个空格后，最简单的办法就是将所有字符串前移。以此类推，直到所有空格被处理完毕。

还有一种更为快速的办法，就是交换空格和非空格的值，依次类推，时间复杂度为n

```c++
  1 #include <iostream>
  2 
  3 void strip_space(char* str, int count) {
  4     for (int i = 0; i < count; i++) {
  5         // 找到第一个空格
  6         if (str[i] == ' ') {
  7             // 为这个空格找到第一个非空格的字符
  8             bool find = false;
  9             for (int j = i + 1; str[j] != '\0'; j++) {
 10                 if (str[j] != ' ') {
 11                     // 交换
 12                     *(str + i) = str[j];
 13                     *(str + j) = ' ';
 14                     find = true;
 15                     break;
 16                 }
 17             }
 18             if (!find) {
 19                 // 如果这个空格后面再也找不到非空格字符，结束
 20                 str[i + 1] = '\0';
 21                 break;
 22             }
 23         }
 24     }
 25 }
 26 
 27 using namespace std;
 28 int main(int argc, char* argv[]) {
 29     char str[] = " a 000 1 1 4 5 . &";
 30     cout << "输入字符串: " << str << endl;
 31     strip_space(str, 18);
 32     cout << "去处空格之后: " << str << endl;
 33 }
```



- 手写链表翻转函数，要求是不用其他辅助存储

### 二叉树的遍历

首先了解二叉树的结构

二叉树遍历分为，前序遍历，中序遍历，后序遍历

当然遍历二叉树之前，我们需要先创建一个二叉树。

二×查找树，当前根节点的左边全部比根节点小，当前根节点的右边全部比根节点大。

比如给定顺序字符串：“G D W S X Y P Q”

按照先序构建，即，先构建根节点，再构建左子，再构建右子。

这里为了要建立一个明确的二叉树，这里我们选择按照二×搜索树前序遍历构造，思路：

第一个元素看做根节点，然后比较第二个元素与根节点元素大小。小于根节点，放在左子树；反之放在右子树。





- 计算二叉树高度
- 字符串转整形
- 写一个lru算法
- 手写算法：多文件内容排序，求根号算法
- 排序时间复杂度
- 红黑树、二叉树、冒泡排序、快速排序
- 给定一个有序的旋转数组，查找某个元素是否在数组内，eg：[4 5 6 1 2 3] target=5
- 给定一个物品在各个时间点的价格，求进行一次买卖之后最大获利；变形为：求多次买卖的最大获利
- 设计一个最优时空复杂度的位循环队列
- 系统位谋进程分配了4个页框，该进程已访问的页号序列为2，0，2，9，3，4，2，8，2，4，8，4，5.若进程要访问的下一页页号为7.依据LRU算法，应淘汰的页号是几号？
- 手写深拷贝实现代码
- 哈夫曼编码
- 有序数组，相同的元素最多保留2个，O（1）的算法
- 手写代码，求链表倒数第K个元素
- 手写代码，求数组中出现次数超过一半的数
- 写一个随机数生成器，能以p概率生成0，1-p概率生成1。利用这个生成器等概率生成0-6.
- 在32gb的内存里对1tb数据排序
- 简单动态规划，排楼梯问题
- 最长公共子序列
- 二维数组，回字形输出
- 一个数组，和sum。求出数组中所有可能的任意元素（一个元素只能用一次）的和等于sum的组合。
- 柱状图求最大矩形面积
- 大整数字符串相乘
- N*N地图随机放X个雷，打印地图，每格显示周边雷的个数
- 给一个有序数组，没有重复值，给一个数组sum，从数组中找出和为sum的两个数，打印出所有可能的组合
- K个排序的列表，融合成一个有序列表
- 两个字符串的公共子串（连续的）长度

# C++11新特性

以下新特性基于C++03和C++11比较，所以，更多相比于C++98的特性是没有被体现出来的

## Initiallizer list

```c++
//c++03
std::vector<int> v;
v.push_back(2);
v.push_back(3);

//c++ 11
std::vector<int> v{ 1,2,3 };
```

## auto type

自动类型推导

```c++
std::vector<int> vec = { 1,2,3,4 };
//c++ 03
for (std::vector<int>::iterator it = vec.begin(); it != vec.end(); it++) {
  std::cout << *it << std::endl;
}

//c++ 11
for (auto it = vec.begin(); it != vec.end(); it++) {
  std::cout << *it << std::endl;
}

auto a = 3 + 2;
auto s = "123";
```

使用auto需要注意以下两点：

- auto声明的变量必须要初始化，否则编译器不能判断变量的类型
- auto不能被声明为返回值，auto不能作为形参，auto態被修饰为模板参数

auto实际上是在编译时对变量进行了类型推导，所以不会对程序的运行效率造成不良影响。另外，auto并不会影响编译速度，因为编译时本来也要右侧推导然后判断是否与左侧是否匹配。

## decltype

有时我们希望从表达式的类型推断出要定义的变量类型，但是不想用该表达式的值初始化变量（初始化可以用`auto`）。为了满足这一需求，C++11新标准引入了`decltype`类型说明符，它的作用是选择并返回操作数的数据类型，在此过程中，编译器分析表达式并得到它的类型，却不实际计算表达式的值。

## foreach

```c++
std::vector<int> vec = { 1,2,3,4 };
//c++ 03
for (std::vector<int>::iterator it = vec.begin(); it != vec.end(); it++) {
  std::cout << *it << std::endl;
}

//c++ 11
//read only（只读）
for (auto i : vec) {
  std::cout << i << std::endl;
}
//只读
for (const auto& i : vec) {
  std::cout << i << std::endl;
}
//changes the values in v（修改）
for (auto& i : vec) {
  i = 3;
}
```

## nullptr

nullptr代替了C++03的enum，更安全

## enum class

enum代替了C++03的enum，更安全

```c++
//c++ 03
enum ship {
  bulkship,
  tankership
};

//c++ 11
enum class ship1 {
  bulkship,
  tankership
};
```

## override

override关键标识for virtual function（更加安全，直观）

```c++
class base {
public:
	virtual void fun1(int);
	virtual void fun2() const;
	void fun3(int);
};

class son :public base {
	//c++ 03 存在隐患
	/*
	void fun1(float);  //不小心写错了参数,ok 编译通过，create a new func
	void fun2();       //不小心少写了const,ok 编译通过，create a new func
	void fun3();
	*/

	// but in c++ 11 更安全清晰
	void fun1(float) override; //编译Error: no func to override
	void fun2() override;      //编译Error: no func to override
	void fun3() override;      //编译Error: no func to override			
};
```

## final

final关键标识，主要是class及virtual function

```c++
//this is means no class can be derived from CPoint2D
class CPoint2D final {
	//No class can override Draw
	virtual void Draw() final;
};
```

## default

关键字default标识，compiler generated default constructer

强制编译器生成默认构造函数

- 编译器不再生成默认构造函数

```c++
class CPoint2D {
public:
	CPoint2D(double x_,double y_) {
		x = x_;
		y = y_;
	}
	double x;
	double y;
};

int main(){	
	CPoint2D pt;//编译报错，不存在默认构造函数，因为编译器不再生成	
}
```

- 通过default强制生成

```c++
class CPoint2D {
public:
	CPoint2D(double x_,double y_) {
		x = x_;
		y = y_;
	}
	CPoint2D() = default;//告诉编译器强制生成
	double x;
	double y;
};

int main(){	
	CPoint2D pt;//ok	
}
```

## delete

关键标识delete，放在函数后面，表示函数不能被调用。

- 看以前的情形，构造函数只接受int，但是输入double也是可以的，因为会自动转换

```c++
class dog {
public:
	dog(int age_) {
		age = age_;
	}
	int age;
};

int main(){	
	dog(2);   //ok
	dog(4.5); //also ok,converted form double to int
}
```

- C++11解决方案

```c++
class dog {
public:
	dog(int age_) {
		age = age_;
	}
	dog(double) = delete;
	int age;
};

int main(){	
	dog(2);   //ok
	dog(4.5); //not ok,已经删除的函数
}
```

## Lambda function

让编程更优雅。lambda表达式是匿名函数，可以认为是一个可执行体functor。具体语法：

```shell
[捕获区]（参数区）（代码区）；
```



```c++
int main(){	
	std::cout << [](int x, int y) {return x + y; }(3, 5) << std::endl;
}
```

经常使用std::sort对结构体匹配lambda匿名函数使用，比如点的数组按照x升序排列

```c++
class CPoint2D {
public:
	CPoint2D(double x1,double y1) {
		x = x1; y = y1;
	}
	double x;
	double y;
};
int main(){

	std::vector<CPoint2D> Pts{ {1,1},{3,3},{2,2} };
	std::sort(begin(Pts), end(Pts), [](const CPoint2D& pt1, const CPoint2D& pt2) {
		return  pt1.x < pt2.x;
		});
}
```

## Smart pointer

智能指针，让你从内存的泥潭中解放出来。一共有三种智能指针：

- `shared_ptr`，基于引用计数的智能指针，会统计当前有多少个对象同时拥有该内部指针；当引用计数降为0时，自动释放。使用`use_count()`函数可以看到指针对象被引用次数，存在最大的问题就是`循环引用`：

```c++
class B;
class A
{
public:
　　shared_ptr<B> m_b;
};
 
class B
{
public:
　　shared_ptr<A> m_a;
};
 
int main()
{
　　{
　　　　shared_ptr<A> a(new A); //new出来的A的引用计数此时为1
　　　　shared_ptr<B> b(new B); //new出来的B的引用计数此时为1
　　　　a->m_b = b; //B的引用计数增加为2
　　　　b->m_a = a; //A的引用计数增加为2
　　}
 
　　//b先出作用域，B的引用计数减少为1，不为0，所以堆上的B空间没有被释放，且B持有的A也没有机会被析构，A的引用计数也完全没减少
 
　　//a后出作用域，同理A的引用计数减少为1，不为0，所以堆上A的空间也没有被释放
}
```

- `weak_ptr`，基于引用计数的智能指针，在面对循环引用的问题将无能为力。因此C++11还引入了weak_ptr与之配套，weak_ptr只引用，不计数。当weak_ptr指向一块内存时，对应的强引用指针引用计数并不加一weak_ptr 只能由shared_ptr或者其它的weak_ptr构造weak_ptr和shared_ptr共享一个引用计数对象，在引用计数对象上增加一个weak_count, 但不增加ref_count.引用计数对象当ref_count减至zero时会销毁其管理的资源，weak_ptr可以通过ref_count是否为0来判断指向的资源是否可用。当ref_count和weak_count都为0时引用计数对象会销毁其自身。

```c++
// 默认构造函数
weak_ptr<T> wp1;
// 拷贝构造
weak_ptr<T> wp2(p);	// p为shared_ptr<T>
// =构造
weak_ptr<T> wp3 = wp2
```

- `unique_ptr`，遵循独占语义的智能指针，在任何时间点，资源智能唯一地被一个unique_ptr所占有，当其离开作用域时自动析构。资源所有权的转移只能通过`std::move()`而不能通过赋值符号（因为他将复制构造函数和`=`操作符设为私有）。`release()`函数会删除释放某个`unique_ptr`对象，但是会将指针值返回。当离开作用域之前，会自动调用析构函数，并销毁对象。

还有就是C++98也引入了智能指针的概念：`auto_ptr`

## tuple

元组

- `std::pair<std::string, int>`的扩展版本，可以当做一个通用的结构体来使用
- `tuple`某些情况下会让代码的易读性变差
- 什么情况下使用`tuple`

**std::pair<>的扩展版，可多个参数**

```c++
std::pair<int, std::string> p = std::make_pair(2, "hello");
//std::pair的扩展版
std::tuple<int, std::string, char> t(2,"foo",'a');
auto t1 = std::make_tuple(0, "dog", 'b');
std::cout << std::get<0>(t) << std::endl;
std::cout << std::get<1>(t) << std::endl;
std::cout << std::get<2>(t) << std::endl;
```

**易读性会变差（一个使用结构体，一个使用tuple）**

结构体比较清晰`p1.name` `p1.age`

tuple易读性差，通过`std::get<0>(t2) std::get<1>(t2)`取值

这个语法，会让你看起来并不知道0和1里面存储的是什么

```c++
struct person {
  std::string name;
  int age;
};
person p1;
std::tuple<std::string, int> t2;

//把上面的代码遮挡起来 tuple会导致代码的易读性降低
std::cout << p1.name << p1.age<<std::endl;
std::cout << std::get<0>(t2) << std::get<1>(t2) << std::endl;
//what stored in position 0?  what stored in position 1?
```

**什么时候使用tuple**

比作为函数返回值使用，我们一般不声明结构体

```c++
std::tuple<std::string,int> GetNameAge(){
	return std::make_tuple("lcl", 20);
}
```

当需要比较一个tuple大小的时候

```c++
//comparison of tuples
std::tuple<int, int, int> time1, time2;  
if (time1 > time2) {
  //...
}
```

多索引map

```c++
std::map<std::tuple<int, char, double>, float> m;
```

## thread

线程`#include <thread>`

`std::thread`可以和普通函数和lambda表达式搭配使用。它允许向线程执行函数传递任意多参数。

```c++
#include <thread>
void func() {
 // do some work here
}
int main() {
   std::thread thr(func);
   t.join();
   return 0;
} 
```

函数`func（）`在新起的线程中执行。调用join（）函数是为了阻塞主线程，直到这个新起的线程执行完毕。线程函数的返回值都会被忽略，但线程函数可以接受任意数目的输入参数。

`std::thread`的其他成员函数

- `joinable()`：判断线程对象是否可以join，当线程对象被析构的时候，如果该函数返回`true`，会导致`std::terminate`被调用
- `join()`：阻塞当前进程（通常是主线程），等待创建新的线程执行完毕被操作系统回收
- `detach()`：将线程分离，从此线程对象受操作系统管辖

**线程管理函数**

除了`std::thread`的成员函数外，在`std::this_thread`命名空间也定义了一些列函数用于管理当前线程。

- `get_id`：返回当前线程id
- `yield`：告知调度器运行其他线程，可用于当前处于繁忙的等待状态。相当于主动让出剩下的执行时间，具体的调度算法取决于实现
- `sleep_for`：指定的一段时间内停止当前线程的执行
- `sleep_until`：停止当前线程的执行直到指定的时间点

**unique_lock解决死锁问题**

通过两个unique_lock一起上锁，可以解决死锁问题。

**三种锁的创建类型**

- `defer_lock_t`不需要从属一个`mutex`
- `try_to_lock_t`在没有锁住的情况下尝试获取一个`mutex`
- `adopt_lock_t`假设调用当前锁的线程已经有一个从属`mutex`

## alias

```c++
using func = void (*) (int, int);
```

使用别名

## thread_local

线程本地变量，用于多线程时候，为每一个线程定义一个线程变量。

这是一个关键字，于此同时还有其他关键字：

- `auto`
- `register`这个关键字支持到`C++17`，已经被std所废弃了
- `static`
- `extern`
- `mutable`可变的变量修饰符，突破`const`关键字的限制

**Spring中的Bean默认是单例的，非线程安全**

## Long long

新增加的数值变量类型，目标类型将会以最小不小于64bits的宽度存储

## iterator

迭代器

- `std::begin`
- `std::end`

他们的原理都是基于`initializer_list`初始化列表这个类，简单来说，就是通过begin构造函数，将模板类型所规定的对象进行有序化。生成一个新的迭代器对象。



# 头条要点

1. C++依赖注入（IOC），spring也有类似机制，C++观察者模式
2. C++伪缓存
3. C++ share_ptr 如何解决循环引用的问题，weak_ptr的实现方式
4. mysql主键索引和非主键索引，为什么非主键索引更慢（索引覆盖、索引组织表）
5. 如何用http实现rpc框架的通信（都是7层协议），RPC会自动打解数据包
6. GNU编译器底层对分支代码的优化

编程题：

64 * 64的棋盘，边长为1的正方形，如何通过对角线，画出一个面积为N（比如N为10）的闭合图形。大概有多少种解法。

**简历需要美化**

然后，需要每个项目梳理一到两个点出来，体现技术性的点。

写了这么多，其实真正在面试里面能用到的不是很多，高级别的面试，比较考验真实的解决问题的能力，很多遇到的问题都是面经里面不会提到的。这也是面试官考察一个人能力的重要指标。

# shopee要点

快排（ 递归的栈空间限制），堆排序，动态规划

1. 什么时候会产生TIME_WAIT，什么时候会产生CLOSE_WAIT

2. LRU缓存机制

3. C10K服务端模式

4. ES6搜索（这个不太记得了）

5. 进程切换原理

6. go语言协程实现原理

7. 分布式系统雪崩产生原因，如何防止雪崩

8. tcp拥塞算法

9. 快速排序算法实现原理（口述即可）

10. 微服务和soa的区别，微服务的技术难点

11. 谈谈redis的使用，redis的数据主从同步

12. C++虚函数实现原理

13. C++多态实现原理

14. go语言锁的使用， go语言协程启动匿名函数传入参数的考察（面试官写的代码，让指出错误）

15. 分布式缓存有哪些技术框架

16. 如何解决线上问题，步骤和解决办法（运维知识）

17. 除开gdb以外，有哪些服务端调试手段

18. hash索引的实现原理

19. mysql的innoddb和MyIsam两种引擎的区别（没答上来）

20. mysql数据库索引的实现原理

21. C++编码，运算符重载，漏掉一个编程题

22.编程题，使用python或go实现，1234567，变成字符串“1,124,567”

23.class A{

  int func();

  virtual int func2();

  int a;

};

24. 一台机器只有1G物理内存，是否程序可以获取到2G，为什么。

25. 描述，操作系统虚拟内存是如何实现的

26. vector扩容的原理

27. 什么环节会发送RST包



# wb要点

## 用过什么框架

### spring

轻量级IOC和AOP容器框架，IOC的三种配置方式：

- xml配置
- 基于注解的配置
- 基于java的配置

主要由以下几个模块组成：

- spring core 核心类库，提供IOC服务
- spring context 提供框架式的Bean访问方式，以及企业级功能（JND）
- spring aop AOP服务，把应用业务逻辑和系统服务分开
- spring dao （Data Access Object）对jdbc的抽象，简化了数据访问异常的处理（针对系统而言）
- spring ORM （Object Relation Mapping）对现有的ORM框架的支持（针对开发而言）
- spring web 提供了基本的面向web的综合特性，例如多放文件上传
- spring mvc 提供面向web应用的model-view-controller实现

### Akka

actor模型，使用actor将事务执行流程化，互不影响。actor类似go语言携程。

## Java设计模式

- 微服务架构六种常用设计模式

代理设计模式

聚合设计模式

链条设计模式

聚合链条设计模式

数据共享设计模式

异步消息设计模式

- spring框架中都用到了哪些设计模式

代理模式：在AOP和remoting中被用的比较多

单例模式：在spring配置文件中定义的bean默认为单例模式

模板方法：用来解决代码重复的问题

前端控制器：spring提供了dispatcherservlet来对请求进行分发

视图帮助（view helper）：spring提供一系列的jsp标签，高效宏来辅助将分散的代码整合在视图里

依赖注入：贯穿于BeanFactory/ApplicationContext接口的核心理念

工厂模式：BeanFactory用来创建对象的实例（简单工厂模式）

- 设计模式分类

![image-20200322225221410](/Users/ethancao/Library/Application Support/typora-user-images/image-20200322225221410.png)

#### 适配器模式

作为两个不兼容的接口之间的桥梁。它结合了两个独立接口的功能。适配器模式提供对接口的转换。如果你的客户端使用某些接口，但是你有另外一些接口，你就可以写一个适配器来连接这些接口。

![image-20200322233421890](/Users/ethancao/Library/Application Support/typora-user-images/image-20200322233421890.png)

举例：

```java
//file 为已定义好的文件流 
FileInputStream fileInput = new FileInputStream(file); 
InputStreamReader inputStreamReader = new InputStreamReader(fileInput);
```

以上就是适配器模式的体现，FileInputStream是字节流，而并没有字符流读取字符的一些API，因此通过InputStreamReader将其转为Reader子类，因此有了可以操作文本的文件方法。

- 类的适配器模式

原理：通过继承特性来实现适配器功能

- 对象的适配器模式

原理：通过组合方式来实现适配器功能

- 接口的适配器模式

原理：借助抽象类来实现适配器功能

#### 适配器模式与装饰器模式有什么区别

虽然适配器模式和装饰器模式的结构类似，但是每种模式的出现意图不同。适配器模式被用于桥接两个接口，而装饰模式的目的是在不修改类的情况下给类增加新的功能。

装饰者模式举例：

```java
BufferedReader bufferedReader=new BufferedReader(inputStreamReader);
```

构造了缓冲字符流，将FileInputStream字节流包装为BufferedReader过程就是装饰的过程，刚开始的字节流FileInputStream只有一个字节方法，包装为inputStreamReader后，就有了读取一个字符的功能在包装为BufferedReader后，就拥有了read一行字符的功能。

## 数据库索引（MySQL）

- 索引的原理

1. B+树索引 二叉搜索树这棵树是平衡二叉树 N叉树为了减少树高

如果语句是 `select * from T where ID = 500`，即逐渐查询方式，则只需要搜索ID 这颗B+树

如果语句是`select * from where k = 5`，即普通索引查询方式，则**需要先搜索k索引树，ID的值为500，再到ID索引树搜索一次。这个过程称回表**

也就是说，基于非主键索引的查询**需要多扫描一颗索引树，因此，我们在应用中应该尽量使用主键查询**。

2. 一个数据页满了，按照B+ Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率大概50%

当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程

3. 从性能和存储空间方面考量，自增主键往往是更合理的选择
4. 显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

因此，自增主键比较合适

- 索引分类

普通索引：没有任何限制

唯一索引：索引列的值必须唯一，但允许有控制（unique index）

主键索引：特殊的唯一索引，不允许有空值，建表自动创建主键索引

组合索引：多字段联合创建索引，组合索引大部分情况比单列索引块（比如我们刚好查的就是建立了组合索引的那几列）

- 如何创建索引

1. 使用create index
2. 使用create table 创建表的时候添加索引

- 为什么要创建索引

1. 毋庸置疑提高插入和查询的速度

- 索引有什么缺点

1. 降低更新速度（不仅要更新数据，还要更新索引）
2. 占磁盘空间、内存空间

- 索引覆盖

```sql
create table T(
  ID int primary key,
	k int Not NULL default 0,
  s varchar(16) not null default '',
  index k(k)
) engine = InnoDB;
```

`select * from T where k between 3 and 5`这种查询K的索引搜索到主键，然后搜索主键的索引拿到具体的信息有回表。

`select ID from T where k between 3 and 5`这时只需要查ID的值，而ID的值已经在k索引树上，因此可以直接提供查询结果，不需要回表，由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用**覆盖索引是一个常用的性能优化手段**。

如何索引覆盖？简单来说创建索引的时候，覆盖掉所有可能查询到的“列”名。

如何查看当前select操作是否使用了索引覆盖？很简单，当查询非主键列的时候，使用`EXPLAIN`查看语句的Extra列可以看到“Using Index”的信息。则使用了索引覆盖。

- 索引优化

1. 减少主键字段长度（非主键索引字段也是）
2. 建立联合索引
3. 覆盖索引对InnoDB尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引包含查询所需的数据，就不再需要在聚集索引中查找了

- 索引数据结构

B-Tree

- 索引使用

如果你非要使用`like`，那么`like "%aaa%"`不会使用索引，而`like "aaa%"`会

不要在单列上进行运算，否则索引失效

不要使用NOT IN和<>操作

## MySQL数据引擎区别

- MyISAM

保存成文件形式，适合跨平台

锁粒度是表级别

支持全文索引

非事务安全

- InnoDB

事务安全

支持行级锁

不支持全文索引

比MyISAM复杂

- 使用场景

1. MyISAM适合执行大量的select操作，可以选择MyISAM
2. 如果需要大量insert和update操作，可以选择InnoDB

## Java异常处理

异常分类：

![image-20200322215224416](/Users/ethancao/Library/Application Support/typora-user-images/image-20200322215224416.png)

**两个子类区别：**

1. **Error**： 程序不应该捕捉的错误，应该交由JVM来处理。一般可能指非常重大的错误。这个错误我们一般获取不到，也无法处理！

2. **Exception**：程序中应该要捕获的错误。这个异常类及它的子类是我们需要学习获取要处理的。

   （1）RuntimeException：运行时异常，也叫未检查异常，是Exception的子类，但不需捕捉的异常超类，但是实际发生异常时，还是会导致程序停止运行的，只是编译时没有报错而已。比如除数为零，数组空指针等等，这些都是在运行之后才会报错。此类异常，可以处理也可以不处理，并且可以避免。

   （2）在Exception的所有子类中 除了RuntimeException类和它的子类，其他类都叫做非运行时异常，或者叫已检查异常，通常被定义为Checked类，是必须要处理可能出现的异常，否则编译就报错了。Checked类主要包含：IO类和SQL类的异常情况，这些在使用时经常要先处理异常（使用throws或try catch捕获）。

**java几种常见的异常：**
**运行时异常：**
1，java.lang.ArrayIndexOutOfBoundsException 数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。
2，ArithmeticException 算术错误情形，如以零作除数，算术条件异常。
3 java.lang.SecurityException 安全性异常
4，IllegalArgumentException 方法接收到非法参数，非法参数异常！
5，java.lang.ArrayStoreException 数组中包含不兼容的值抛出的异常
6，java.lang.NegativeArraySizeException 数组长度为负异常
7 java.lang.ClassNotFoundException 找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。
8 java.lang.NullPointerException 空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等。
9，java.lang.NumberFormatException（数字格式转换异常）
10，java.lang.ClassCastException(强制类型转换异常)

**IOException**
1， IOException 操作输入流和输出流时可能出现的异常
2， EOFException 文件已结束异常
3， FileNotFoundException 文件未找到异常

**如何处理异常**

try、catch和finally三个关键字，这三个关键字可以组合使用：

`try--catch`

`try--catch--finally`

`try--finally`

`throws`关键字表示，该方法不处理异常，而由系统自动将所捕获的异常信息抛给上级调用方法。

`throw`关键字作用是手工跑出异常类的实例化对象。`throw`通常和`throws`联合使用，抛出的是程序中已经产生的异常类实例。

自定义异常方法，继承自`Exception`类。

## 抽象类和接口区别

1. 一个类可以实现多个接口，但是只可以继承一个抽象类
2. 抽象类可以包含具体方法，接口的所有方法都是抽象的
3. 抽象类可以声明和使用字段，接口则不能，但接口可以创建静态的final常量
4. 接口的方法都是public的，抽象类的方法可以是public、protected、private或者默认的package
5. 抽象类可以定义构造函数，接口却不能

总结来说，java的接口有点像C++的完全由纯虚函数构成的抽象类

## 除了单例模式你在生产中还用过什么模式

一般来说，依赖注入，工厂模式，装饰模式或者观察者模式。

- 抽象工厂模式

工厂方法模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。

其实简而言之，就是在原来工厂模式的基础上，在原工厂类的基础上，添加一个抽象方法（接口），这个方法被用来在新添加的工厂类继承旧的工厂类的时候，实现该方法以实现新加入的功能。

- 观察者模式

包含四个角色：

1. 抽象被观察者角色：也就是一个抽象主题，它把所有对观察者对象的引用保存在一个集合中，每个主题都可以有任意数量的观察者。抽象主题提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。
2. 抽象观察者角色：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。
3. 具体被观察者角色：也就是一个具体的主题，在集体主题的内部状态改变时，所有登记过的观察者发出通知。
4. 具体观察者角色：实现抽象观察者角色所需要的更新接口，一边使本身的状态与制图的状态相协调。

简单来说就是设置一个接口，包含`注册观察者`、`移除观察者`、`通知观察者`这三个能力的接口。

然后定义一个被观察者继承这个接口。

定义一个观察者接口，观察者接口，最基本的功能就是收到`通知消息`并作出动作。这个抽象接口，必须被`通知观察者`调用

定义一个观察者继承观察者接口。

## 假如问到代码习惯

- 开闭原则

开闭原则就是说对扩展开放、对修改关闭。为了使程序的扩展更好，易于维护和升级。想要达到这样效果，我们需要使用接口和抽象类。

- 里氏代换原则

面向对象设计的基本原则之一。简单来说，任何基类可以出现的地方，子类一定可以出现（替换），而不影响软件的功能。

- 依赖倒置原则

这个是开闭原则的基础，针对接口编程，依赖于抽象而不是依赖于具体

- 接口隔离原则

使用多个隔离的接口，比使用单个接口要好。降低耦合度，降低依赖。这个有点像Unix哲学，只做一件事情。

- 最少知道原则

一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。还是降低耦合，降低依赖

- 合成复用原则

尽量使用合成、聚合的方式（C++叫组合），而不是使用继承

## 为什么要使用单例

1. 核心交易，不允许多实例运行
2. 省去new操作，降低GC压力，以及系统开销

## Spring AOP

AOP是Spring框架面向切面的编程思想，AOP采用一种称为“横切”的技术，将涉及多业务流程的通用功能抽取并单独封装，形成独立的“切面”，在核实的实际将这些切面横向切入到业务流程指定的位置中。

例如：

在一个业务系统中，用户登录是基础功能，凡是涉及到用户的业务流程都要求用户进行系统登录。如果把用户登录功能代码写入到每个业务流程中，会造成代码冗余，维护也非常麻烦，当需要修改用户登录功能时，就需要修改每个业务流程的用户登录代码，这种处理方式显然是不可取的。比较好的做法是把用户登录功能抽取出来，形成独立的模块，当业务流程需要用户登录时，系统自动把登录功能切入到业务流程中。

AOP也是需要xml配置文件配置的（aop.xml），此外还需要引入jar包（aop包）

读写分离也可以用AOP来做

AOP相关概念：

> (1)横切关注点：对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点
>  (2)Aspect(切面):通常是一个类，里面可以定义切入点和通知
>  (3)JointPoint(连接点):程序执行过程中明确的点，一般是方法的调用。被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器
>  (4)Advice(通知):AOP在特定的切入点上执行的增强处理，有before(前置),after(后置),afterReturning(最终),afterThrowing(异常),around(环绕)
>  (5)Pointcut(切入点):就是带有通知的连接点，在程序中主要体现为书写切入点表达式
>  (6)weave(织入)：将切面应用到目标对象并导致代理对象创建的过程
>  (7)introduction(引入)：在不修改代码的前提下，引入可以在**运行期**为类动态地添加一些方法或字段
>  (8)AOP代理(AOP Proxy)：AOP框架创建的对象，代理就是目标对象的加强。Spring中的AOP代理可以使JDK动态代理，也可以是CGLIB代理，前者基于接口，后者基于子类
>  (9)目标对象（Target Object）: 包含连接点的对象。也被称作被通知或被代理对象。POJO

AOP使用场景：

> *Authentication 权限*
>  *Caching 缓存*
>  *Context passing 内容传递*
>  *Error handling 错误处理*
>  *Lazy loading　懒加载*
>  *Debugging　　调试*
>  *logging, tracing, profiling and monitoring　记录跟踪　优化　校准*
>  *Performance optimization　性能优化*
>  *Persistence　　持久化*
>  *Resource pooling　资源池*
>  *Synchronization　同步*
>  *Transactions 事务*

## Spring ORM

对象关系映射（Object Relation Mapping），用于实现面向对象编程语言里不同类型系统的数据之间转换。简单点来说，就是将关系型数据库的表变为Java代码里面的类对象，便于程序操作，而且，对不同数据库是可以适配和移植的。

## 如何保证kafka的消息机制

Producer生产者，只负责数据生产，生产者的代码可以集成到任务系统中

数据的分发策略由producer决定，默认是defaultPartition Utils.abs(key.hasCode) % numPartitions

Broker：当前服务器上的kafka进程，只管数据存储，不管是谁生产，不管是谁消费。在集群中每个broker都有一个唯一brokerid，不得重复

Topic：目标发送的目的地，这是一个逻辑概念，落到磁盘上是一个partition的目录。partition的目录中有多个segment组合（index，log）

一个topic对应多个partition[0,1,2,3]，一个partition对应多个segment组合。一个segment有默认的大小是1G。

每个partition可以设置多个副本，会从所有的副本中选取一个leader出来。所有读写操作都是通过leader来进行的。这是特别要强调的一点，mysql做主从一般都是为了读写分离。

ComsumerGroup：数据消费组，ConsumerGroup可以有多个，每个ConsumerGroup消费的数据都是一样的。

可以把多个consumer线程划分为一个组，组里面所有成员共同消费一个topic的数据，组员之间不能重复消费。

**如何保证数据完全生产？**

ACK机制：broker表示发来的数据已经确认接收无误，表示数据已经保存到磁盘。

0：不等待broker返回确认消息

1：等待topic中某个partition leader保存成功的状态反馈

-1：等待topic中某个partition所有副本都保存成功的状态反馈

**broker如何保存数据？**

在理论环境下，broker按照顺序读写的机制，可以每秒保存600M的数据。主要通过pagecache机制，尽可能的利用当前物理机器上的空闲内存来做缓存。

当前topic所属的broker，必定有一个该topic的partition，partition是一个磁盘目录。partition的目录中有多个segment组合（index，log）

**consumerGroup的组员和partition之间如何做负载均衡？**

最好是一一对应，一个partition对应一个consumer

如果consumer的数量过多，必然会产生空闲的consumer。

**如何保证kafka消费者消费数据是全局有序的？**

伪命题

如果要全局有序，必须保证生产有序，存储有序，消费有序。

由于生产可以集群部署，存储可以分片，消费可以设置为一个comsumerGroup，要保证全局有序，就需要保证每个环节都有序。

只有一个可能，就是一个生产者，一个partition，一个消费者。

**为什么ack=1，消息也会丢失？**

kafka消息丢失的几种情况

网络异常：

acks设置为0时，不和kafka集群进行消息接收确认，当网络发生异常等情况时，存在消息丢失的可能

客户端异常：

异步发送时，消息并没有发送至kafka集群，而是在client端按一定规则缓存并批量发送。在这期间，如果客户端发生死机等情况，都会导致消息的丢失。

缓冲区满了：

异步发送时，client端缓存的消息超出了缓冲池的大小，也存在消息丢失的可能。

Leader副本异常：

ack=1的情况下，producer只要收到分区leader成功写入的通知就会认为消息发送成功了。如果leader成功写入后，还没来得及把数据同步到follower节点就挂了，这时候消息就丢失了。

日常应用中，我们需要结合自身的应用场景来选择不同的配置。

想要更高的吞吐量就设置：异步，ack=0；

想要不丢失消息数据就选：同步，ack=-1策略；

## 操作系统线程、go语言携程、actor区别

**传统多数流行的语言并发是基于多线程之间的共享内存, 使用同步方法防止写争夺, Actors使用消息模型, 每个Actor在同一时间处理最多一个消息, 可以发送消息给其他Actor, 保证了单独写原则。从而巧妙避免了多线程写争夺。和共享数据方式相比, 消息传递机制最大的优点就是不会产生数据竞争状态。**

**实现消息传递有两种常见的类型：**

**基于channel（golang为典型代表）的消息传递（CSP模型--Communicating Sequential Processes）**

**基于Actor（erlang为代表）的消息传递**

**二者的格言都是："Don’t communicate by sharing memory, share memory by communicating"**

那么他们有什么区别呢？

- Actor

在Actor模型中，主角是Actor，类似一种worker，Actor彼此之间直接发送消息，**不需要经过什么中介**，消息是异步发送和处理的。

Actor模型描述了一组为了避免并发编程的常见问题公理：

1. 所有Actor状态是Actor本地的，外部无法访问
2. Actor必须只有通过消息传递进行通信
3. 一个Actor可以响应消息：推出新Actor，改变其内部状态，或将消息发送到一个或多个其他参与者。
4. Actor可能会堵塞自己，但Actor不应该堵塞它运行的线程。

- Channel

Channel模型中，worker之间不直接彼此联系，而是通过不同channel进行消息发布和侦听。消息的发送者和接受者之间**通过Channel松耦合**，发送者不知道自己消息被哪个接收者消费了，接受者也不知道是哪个发送者发送的消息。

Go语言的CSP模型是由携程Goroutine与通道Channel实现：

1. Go携程goroutine：是一种轻量线程，它不是操作系统的线程，而是将一个操作系统线程**分段使用**，通过**调度器**实现协作式调度。是一种绿色线程，微线程，它与Coroutine携程也有区别，能够在发现堵塞后启动新的微线程。
2. 通道channel：类似Unix的Pipe，用于携程之间通讯和同步。携程之间虽然解耦，但是他们和Channel有着耦合。



Actor之间是直接通讯的，而CSP（go携程）是通过Channel通讯，在耦合度上两者是有区别的，后者更加松耦合。

同时，他们都是

## 无锁实现多线程实现一个唯一数

乐观锁

## flink处理来自两个数据源的数据

A服务处理修改密码的请求，B服务处理放款的请求，两个数据流都输出服务处理数据到两个不同的kafka topic，但是修改密码5分钟之内不允许执行放款操作。请问怎么实现？

分别将A、B两个服务的kafka数据，接到flink的两个数据流里面，B数据stream按照时间窗口五分钟join A数据stream，如果发现五分钟内A进行过修改密码的工作，B stream业务层可以置位redis状态。B服务接收请求的时候判断redis状态，如果状态不对，则服务返回不允许操作。

不过感觉这个问题，不应该使用这种flink的操作去做，应该从服务层面去做。

比如，A收到请求后，redis记录当前操作timestamp，B请求后查询redis根据请求类型以实现频控。

## 乐观锁

- 什么场景下需要使用锁？

在多节点部署或者多线程执行时，同一个时间可能有多个线程更新相同数据，产生冲突，这就是并发问题。这样情况下会出现以下问题：

更新丢失：一个事物更新数据后，被另一个更新数据的事务覆盖

脏读：一个事务读取另一个事务为提交的数据，即为脏读。

其次还有幻读。

针对并发引入并发控制机制，即加锁。

加锁的谜底是在同一个时间只有一个事务在更新数据，通过锁独占数据的修改权。

- 锁的实现方式

1. 悲观锁，前提是，一定会有并发抢占资源，强行独占资源，在整个数据处理过程中，将数据处于锁定状态。
2. 乐观锁，一段执行逻辑加上乐观锁，不同线程同时执行时，可以同时进入执行，在最后更新数据的时候要检查这些数据是否被其他线程修改了（版本和执行初是否相同），没有修改则进行更新，否则放弃本次操作。

当然，还有其他的锁机制，暂时不多介绍，着重于乐观锁的实现。

乐观锁，使用版本标识来确定读到的数据与提交时的数据是否一致。提交后修改版本标识，不一致时可以采取丢弃和再次尝试的策略。

```java
package com.webank.test;

public class OptimiseLock {
    public static int value = 0;

    /**
     * A线程要执行的方法
     * @param Avalue
     * @param i
     * @throws InterruptedException
     */
    public static void invoke(int Avalue, String i) throws InterruptedException {
        Thread.sleep(1000L);
        // 判断value版本
        if (Avalue != value) {
            System.out.println(Avalue + ":" + value + "A版本不一致，不执行");
            value--;
        } else {
            Avalue++;
            value = Avalue;
            System.out.println(i + ":" + value);
        }
    }

    public static void invoke2(int Bvalue, String i) throws InterruptedException {
        Thread.sleep(1000L);
        if (Bvalue != value) {
            System.out.println(Bvalue + ":" + value + "B版本不一致，不执行");
        } else {
            System.out.println("B:利用value运算，value=" + Bvalue);
        }
    }

    public static void main(String[] args) throws InterruptedException {
        new Thread(new Runnable() {
            public void run() {
                try {
                    for (int i = 0; i < 3; i++) {
                        int Avalue = OptimiseLock.value;    // A获取的value
                        OptimiseLock.invoke(Avalue, "A");
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();

        new Thread(new Runnable() {
            public void run() {
                try {
                    for (int i = 0; i < 3; i++) {
                        int BValue = OptimiseLock.value;    // B获取的value
                        OptimiseLock.invoke2(BValue, "B");
                    }
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();
    }

}
```



## CAS（Compare And Swap）

只是一种建立在cpu级别的原子指令，能够保证数据的比较和交换的原子性，常见的编译语言都支持。

- C++11

C++11给我们带来的Atomic一系列原子操作类，它们提供的方法能保证具有原子性。这些方法是不可再分的，获取这些变量的值时，永远获得修改前的值或修改后的值，不会获得修改过程中的中间数值。

​    这些类都禁用了拷贝构造函数，原因是原子读和原子写是2个独立原子操作，无法保证2个独立的操作加在一起仍然保证原子性。

​    这些类中，最简单的是atomic_flag（其实和atomic<bool>相似），它只有test_and_set()和clear()方法。其中，test_and_set会检查变量的值是否为false，如果为false则把值改为true。

​    除了atomic_flag外，其他类型可以通过atomic<T>获得。atomic<T>提供了常见且容易理解的方法：

1. store
2. load
3. exchange
4. compare_exchange_weak
5. compare_exchange_strong

​    store是原子写操作，而load则是对应的原子读操作。

​    exchange允许2个数值进行交换，并保证整个过程是原子的。

​    **而compare_exchange_weak和compare_exchange_strong则是著名的CAS（compare and set）**。参数会要求在这里传入期待的数值和新的数值。它们对比变量的值和期待的值是否一致，如果是，则替换为用户指定的一个新的数值。如果不是，则将变量的值和期待的值交换。

​    weak版本的CAS允许偶然出乎意料的返回（比如在字段值和期待值一样的时候却返回了false），不过在一些循环算法中，这是可以接受的。通常它比起strong有更高的性能。

## 无锁队列

使用c++11实现无锁队列，无锁队列的基本原理就是CAS（交换和保存原子操作）。

以下是一个用c++实现的无锁队列版本。

```c++
EnQueue(x)//进队列
{
    //准备新加入的结点数据
    q = newrecord();
    q->value = x;
    q->next = NULL;
 
    do{
        p = tail; //取链表尾指针的快照
    }while( CAS(p->next, NULL, q) != TRUE); //如果没有把结点链上，再试
 
    CAS(tail, p, q); //置尾结点
}
```

我们可以看到，程序中的那个do-while的重试循环。很可能我在队列尾加入结点时，别的线程已经加入成功了，于是我的CAS返回了false，于是程序再试，直到试成功为止。这个很像我们的抢电话热热线不停地重拨的情况。

你会看到，为什么我们的“置尾结点”的操作不用判断是否成功，因为：

1. 如果有一个线程T1，它的while中的CAS如果成功的话，那么其他所有的随后线程的CAS都会失败，然后就会再循环。
2. 此时，如果T1线程还没有更新tail指针，其它的线程继续失败，因为tail->next不是NULL了（因为首先拿到的tail快照没有更新）。
3. 直到T1线程更新完tail指针，于是其他的线程中的某个线程就可以得到新的tail指针，继续往下走。

细心的同学会发现一个问题——**如果T1线程在利用CAS更新tail指针之前，线程就挂掉了，那么其他线程就进入死循环了。**

下面是改良版的无锁队列：

```c++
EnQueue(x)//进队列改良版
{
    q = newrecord();
    q->value = x;
    q->next = NULL;
 
    p = tail;
    oldp = p
    do{
        while(p->next != NULL)
            p = p->next;
    }while( CAS(p.next, NULL, q) != TRUE); //如果没有把结点链上，再试
 
    CAS(tail, oldp, q); //置尾结点
}
```

我们让每个线程，自己fetch指针p到链表尾。但是这样的fetch会影响性能。而通常实际情况看下来，99.9%的情况不会有线程停转的情况，所以，更好的做法是，你可以结合上述的两个版本，如果retry的次数超过一个值的话（比如说3次），那么就自己fetch指针。

## CAS的ABA问题

描述：

1. 进程P1在共享变量中读到值为A
2. P1被抢占了，进程P2执行
3. P2把共享变量的值从A改成了B，再改回到A，此时P1抢占
4. P1回来看到共享变量里的值没有被改变，于是继续执行

这里的核心问题就是：

1. 不违反CAS使用原则，同一时间，只有一个任务能够操作变量
2. P2拿着变量做了其他事情，P1并不知道

# TC要点

### C++的stl里面队列和链表区别

队列是一个逻辑层面的数据结构，链表是一个实现层面的数据结构

队列可以用链表实现，也可以用数组实现

C++ STL中也有queue，属于container adapter。它内部可以使用序列式容器来实现，比如list。

这样queue的各项操作，实际上就是转换为对内部容器的对应调用。



### go语言问了interface使用场景及与java接口区别





http请求在浏览器发出后如何工作

视频解码项目中的优化措施

tcp拥塞控制

 const的实现机制

技术基础知识点和算法题（链表反转，全部反转和部分反转）

聊做的项目，一步一步分析，怎么实现，可优化的地方。

redis缓存相关技术点。

项目的架构的设计，实现的逻辑是什么样的。

分布式架构，优化方案

# 代码调试

- 使用intellij debug
- 或者配置maven spring boot为开启debug模式，其实就是java虚拟机的启动参数注入

